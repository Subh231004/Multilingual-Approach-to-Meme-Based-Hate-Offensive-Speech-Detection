{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"17npCa0EMxsQvsZyzD6P4Be0u5SCYU90q","authorship_tag":"ABX9TyNXIa0ULYsWdXmBr91bpmZn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":321},"id":"HpbPdg8CI8hw","executionInfo":{"status":"error","timestamp":1753506812153,"user_tz":-330,"elapsed":121577,"user":{"displayName":"Kunal Goswami","userId":"06144718323032899612"}},"outputId":"b59b6cd8-34de-4cbc-ed83-681f908d2366"},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"mount failed","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1-1408506528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         )\n\u001b[0;32m--> 277\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: mount failed"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["# Vulgar\n","\n","import pickle\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","from imblearn.over_sampling import ADASYN\n","import xgboost as xgb\n","\n","# ========== CONFIG ==========\n","train_feature_pkl = '/content/drive/MyDrive/Resnet_Method/Hindi_Image_Features_R101.pkl'\n","test_feature_pkl  = '/content/drive/MyDrive/Resnet_Method/Test_Hindi_Image_Features_R101.pkl'  # ⬅️ Pre-extracted test features\n","train_csv_path    = '/content/drive/MyDrive/Datasets/HASOC-2025/Train/Hindi_train_2025/Hindi_train_data.csv'\n","test_csv_path     = '/content/drive/MyDrive/Datasets/HASOC-2025/Test/Hindi_test_2025/Hindi_test_data_wo_label.csv'\n","# ============================\n","\n","# Load pre-extracted image features\n","with open(train_feature_pkl, 'rb') as f:\n","    train_feature_dict = pickle.load(f)\n","\n","with open(test_feature_pkl, 'rb') as f:\n","    test_feature_dict = pickle.load(f)\n","\n","# Load training labels\n","df = pd.read_csv(train_csv_path)\n","df['Ids'] = df['Ids'].astype(str)\n","\n","# Filter for matching training features\n","train_ids = set(train_feature_dict.keys())\n","df_filtered = df[df['Ids'].apply(lambda x: x.split('.')[0] in train_ids)].copy()\n","\n","# Prepare training data\n","X, y = [], []\n","for _, row in df_filtered.iterrows():\n","    fname = row['Ids'].split('.')[0]\n","    X.append(train_feature_dict[fname])\n","    y.append(row['Vulgar'])\n","\n","X = np.array(X)\n","y = np.array(y)\n","\n","# Encode class labels\n","label_encoder = LabelEncoder()\n","y_encoded = label_encoder.fit_transform(y)\n","\n","# Balance using ADASYN\n","adasyn = ADASYN(random_state=42)\n","X_bal, y_bal = adasyn.fit_resample(X, y_encoded)\n","\n","# Train XGBoost Classifier\n","xgb_classifier = xgb.XGBClassifier(\n","    n_estimators=300,\n","    learning_rate=0.05,\n","    max_depth=10,\n","    subsample=0.9,\n","    colsample_bytree=0.9,\n","    scale_pos_weight=1,\n","    use_label_encoder=False,\n","    eval_metric='logloss',\n","    random_state=36\n",")\n","\n","xgb_classifier.fit(X_bal, y_bal)\n","\n","# Load Test Metadata\n","test_df = pd.read_csv(test_csv_path)\n","test_df['Ids'] = test_df['Ids'].astype(str)\n","\n","# Match with test feature dictionary\n","X_test = []\n","matched_ids = []\n","\n","for _, row in test_df.iterrows():\n","    fname = row['Ids'].split('.')[0]\n","    if fname in test_feature_dict:\n","        X_test.append(test_feature_dict[fname])\n","        matched_ids.append(row['Ids'])\n","\n","X_test = np.array(X_test)\n","\n","# Predict\n","y_test_pred = xgb_classifier.predict(X_test)\n","y_test_label = label_encoder.inverse_transform(y_test_pred)\n","\n","# Prepare final DataFrame\n","result_df = pd.DataFrame({'Ids': matched_ids, 'Vulgar': y_test_label})\n","\n","# Save to Google Drive\n","output_path = '/content/drive/My Drive/Hasoc_Result-2025/Hindi_Predictions_Result_using_Resnet.csv'\n","result_df.to_csv(output_path, index=False)\n","print(f\"\\nPredictions saved to: {output_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":445},"id":"py9hBt1rJJJ8","executionInfo":{"status":"error","timestamp":1753516330098,"user_tz":-330,"elapsed":14091,"user":{"displayName":"Kunal Goswami","userId":"06144718323032899612"}},"outputId":"cd3fee40-eb2f-4cc5-c9f1-610ab532870d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [07:51:57] WARNING: /workspace/src/learner.cc:738: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  bst.update(dtrain, iteration=i, fobj=obj)\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-11-3744409817.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m )\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0mxgb_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_bal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_bal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;31m# Load Test Metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[1;32m   1680\u001b[0m             )\n\u001b[1;32m   1681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1682\u001b[0;31m             self._Booster = train(\n\u001b[0m\u001b[1;32m   1683\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m                 \u001b[0mtrain_dmatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2246\u001b[0m             _check_call(\n\u001b[0;32m-> 2247\u001b[0;31m                 _LIB.XGBoosterUpdateOneIter(\n\u001b[0m\u001b[1;32m   2248\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2249\u001b[0m                 )\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["#Abuse\n","# Vulgar Detection with XGBoost (Corrected: Separate Test Feature Loading)\n","\n","import pickle\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","from imblearn.over_sampling import ADASYN\n","import xgboost as xgb\n","\n","# ========== CONFIG ==========\n","train_feature_pkl = '/content/drive/MyDrive/Resnet_Method/Hindi_Image_Features_R101.pkl'\n","test_feature_pkl  = '/content/drive/MyDrive/Resnet_Method/Test_Hindi_Image_Features_R101.pkl'\n","train_csv_path    = '/content/drive/MyDrive/Datasets/HASOC-2025/Train/Hindi_train_2025/Hindi_train_data.csv'\n","test_csv_path     = '/content/drive/MyDrive/Datasets/HASOC-2025/Test/Hindi_test_2025/Hindi_test_data_wo_label.csv'\n","# ============================\n","\n","# Load pre-extracted image features\n","with open(train_feature_pkl, 'rb') as f:\n","    train_feature_dict = pickle.load(f)\n","\n","with open(test_feature_pkl, 'rb') as f:\n","    test_feature_dict = pickle.load(f)\n","\n","# Load training labels\n","df = pd.read_csv(train_csv_path)\n","df['Ids'] = df['Ids'].astype(str)\n","\n","# Filter for matching training features\n","train_ids = set(train_feature_dict.keys())\n","df_filtered = df[df['Ids'].apply(lambda x: x.split('.')[0] in train_ids)].copy()\n","\n","# Prepare training data\n","X, y = [], []\n","for _, row in df_filtered.iterrows():\n","    fname = row['Ids'].split('.')[0]\n","    X.append(train_feature_dict[fname])\n","    y.append(row['Abuse'])\n","\n","X = np.array(X)\n","y = np.array(y)\n","\n","# Encode class labels\n","label_encoder = LabelEncoder()\n","y_encoded = label_encoder.fit_transform(y)\n","\n","# Balance using ADASYN\n","adasyn = ADASYN(random_state=42)\n","X_bal, y_bal = adasyn.fit_resample(X, y_encoded)\n","\n","# Train XGBoost Classifier\n","xgb_classifier = xgb.XGBClassifier(\n","    n_estimators=300,\n","    learning_rate=0.05,\n","    max_depth=10,\n","    subsample=0.9,\n","    colsample_bytree=0.9,\n","    scale_pos_weight=1,\n","    use_label_encoder=False,\n","    eval_metric='logloss',\n","    random_state=36\n",")\n","\n","xgb_classifier.fit(X_bal, y_bal)\n","\n","# Load Test Metadata\n","test_df = pd.read_csv(test_csv_path)\n","test_df['Ids'] = test_df['Ids'].astype(str)\n","\n","# Match with test feature dictionary\n","X_test = []\n","matched_ids = []\n","\n","for _, row in test_df.iterrows():\n","    fname = row['Ids'].split('.')[0]\n","    if fname in test_feature_dict:\n","        X_test.append(test_feature_dict[fname])\n","        matched_ids.append(row['Ids'])\n","\n","X_test = np.array(X_test)\n","\n","# Predict\n","y_test_pred = xgb_classifier.predict(X_test)\n","y_test_label = label_encoder.inverse_transform(y_test_pred)\n","\n","# Prepare final DataFrame\n","result_df = pd.DataFrame({'Ids': matched_ids, 'Abuse': y_test_label})\n","\n","# Save to Google Drive\n","output_path = '/content/drive/My Drive/Hasoc_Result-2025/Hindi_Predictions_Result_using_Resnet.csv'\n","result_df.to_csv(output_path, index=False)\n","print(f\"\\n✅ Predictions saved to: {output_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cy4ljr7ioudY","executionInfo":{"status":"ok","timestamp":1753516548564,"user_tz":-330,"elapsed":199058,"user":{"displayName":"Kunal Goswami","userId":"06144718323032899612"}},"outputId":"b3badfb6-c8fe-415e-d754-71f6fc3725f5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [07:52:30] WARNING: /workspace/src/learner.cc:738: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  bst.update(dtrain, iteration=i, fobj=obj)\n"]},{"output_type":"stream","name":"stdout","text":["\n","✅ Predictions saved to: /content/drive/My Drive/Hasoc_Result-2025/Hindi_Predictions_Result_using_Resnet.csv\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"38ea8bd9","executionInfo":{"status":"ok","timestamp":1753517387219,"user_tz":-330,"elapsed":196162,"user":{"displayName":"Kunal Goswami","userId":"06144718323032899612"}},"outputId":"ff24aeaf-c9a9-4f49-86ef-49ec92a6e9c3"},"source":["#Sarcasm\n","import os\n","import pickle\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder\n","from imblearn.over_sampling import ADASYN\n","import xgboost as xgb\n","\n","# ======= CONFIG ========\n","LABEL_TO_PREDICT = 'Sarcasm'  # 🔁 Change this label for each run\n","train_feature_pkl = '/content/drive/MyDrive/Resnet_Method/Hindi_Image_Features_R101.pkl'\n","test_feature_pkl  = '/content/drive/MyDrive/Resnet_Method/Test_Hindi_Image_Features_R101.pkl'\n","train_csv_path    = '/content/drive/MyDrive/Datasets/HASOC-2025/Train/Hindi_train_2025/Hindi_train_data.csv'\n","test_csv_path     = '/content/drive/MyDrive/Datasets/HASOC-2025/Test/Hindi_test_2025/Hindi_test_data_wo_label.csv'\n","output_csv_path   = '/content/drive/My Drive/Hasoc_Result-2025/Hindi_Predictions_Result_using_Resnet.csv'\n","\n","\n","# --- Load features ---\n","with open(train_feature_pkl, 'rb') as f:\n","    train_feature_dict = pickle.load(f)\n","with open(test_feature_pkl, 'rb') as f:\n","    test_feature_dict = pickle.load(f)\n","\n","# --- Load labels ---\n","df = pd.read_csv(train_csv_path)\n","df['Ids'] = df['Ids'].astype(str)\n","df_filtered = df[df['Ids'].apply(lambda x: x.split('.')[0] in train_feature_dict)].copy()\n","\n","# --- Prepare training data for specific label ---\n","X, y = [], []\n","for _, row in df_filtered.iterrows():\n","    fname = row['Ids'].split('.')[0]\n","    X.append(train_feature_dict[fname])\n","    y.append(row[LABEL_TO_PREDICT])\n","\n","X = np.array(X)\n","y = np.array(y)\n","\n","# --- Encode and balance ---\n","label_encoder = LabelEncoder()\n","y_encoded = label_encoder.fit_transform(y)\n","X_bal, y_bal = ADASYN(random_state=42).fit_resample(X, y_encoded)\n","\n","# --- Train classifier ---\n","xgb_classifier = xgb.XGBClassifier(\n","    n_estimators=300, learning_rate=0.05, max_depth=10,\n","    subsample=0.9, colsample_bytree=0.9, scale_pos_weight=1,\n","    use_label_encoder=False, eval_metric='logloss', random_state=36\n",")\n","xgb_classifier.fit(X_bal, y_bal)\n","\n","# --- Prepare test data ---\n","test_df = pd.read_csv(test_csv_path)\n","test_df['Ids'] = test_df['Ids'].astype(str)\n","X_test = []\n","matched_ids = []\n","\n","for _, row in test_df.iterrows():\n","    fname = row['Ids'].split('.')[0]\n","    if fname in test_feature_dict:\n","        X_test.append(test_feature_dict[fname])\n","        matched_ids.append(row['Ids'])\n","\n","X_test = np.array(X_test)\n","y_test_pred = xgb_classifier.predict(X_test)\n","y_test_label = label_encoder.inverse_transform(y_test_pred)\n","\n","# --- Load or create result DataFrame ---\n","if os.path.exists(output_csv_path):\n","    result_df = pd.read_csv(output_csv_path)\n","else:\n","    result_df = pd.DataFrame({'Ids': matched_ids})\n","\n","# --- Merge new label predictions ---\n","new_label_df = pd.DataFrame({'Ids': matched_ids, LABEL_TO_PREDICT: y_test_label})\n","result_df = result_df.merge(new_label_df, on='Ids', how='outer')\n","\n","# --- Save final results ---\n","result_df.to_csv(output_csv_path, index=False)\n","print(f\"\\n✅ '{LABEL_TO_PREDICT}' predictions added to: {output_csv_path}\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:06:32] WARNING: /workspace/src/learner.cc:738: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  bst.update(dtrain, iteration=i, fobj=obj)\n"]},{"output_type":"stream","name":"stdout","text":["\n","✅ 'Sarcasm' predictions added to: /content/drive/My Drive/Hasoc_Result-2025/Hindi_Predictions_Result_using_Resnet.csv\n"]}]},{"cell_type":"code","source":["#Vulgar\n","import os\n","import pickle\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder\n","from imblearn.over_sampling import ADASYN\n","import xgboost as xgb\n","\n","# ======= CONFIG ========\n","LABEL_TO_PREDICT = 'Vulgar'  # 🔁 Change this label for each run\n","train_feature_pkl = '/content/drive/MyDrive/Resnet_Method/Hindi_Image_Features_R101.pkl'\n","test_feature_pkl  = '/content/drive/MyDrive/Resnet_Method/Test_Hindi_Image_Features_R101.pkl'\n","train_csv_path    = '/content/drive/MyDrive/Datasets/HASOC-2025/Train/Hindi_train_2025/Hindi_train_data.csv'\n","test_csv_path     = '/content/drive/MyDrive/Datasets/HASOC-2025/Test/Hindi_test_2025/Hindi_test_data_wo_label.csv'\n","output_csv_path   = '/content/drive/My Drive/Hasoc_Result-2025/Hindi_Predictions_Result_using_Resnet.csv'\n","# =======================\n","\n","# --- Load features ---\n","with open(train_feature_pkl, 'rb') as f:\n","    train_feature_dict = pickle.load(f)\n","with open(test_feature_pkl, 'rb') as f:\n","    test_feature_dict = pickle.load(f)\n","\n","# --- Load labels ---\n","df = pd.read_csv(train_csv_path)\n","df['Ids'] = df['Ids'].astype(str)\n","df_filtered = df[df['Ids'].apply(lambda x: x.split('.')[0] in train_feature_dict)].copy()\n","\n","# --- Prepare training data for specific label ---\n","X, y = [], []\n","for _, row in df_filtered.iterrows():\n","    fname = row['Ids'].split('.')[0]\n","    X.append(train_feature_dict[fname])\n","    y.append(row[LABEL_TO_PREDICT])\n","\n","X = np.array(X)\n","y = np.array(y)\n","\n","# --- Encode and balance ---\n","label_encoder = LabelEncoder()\n","y_encoded = label_encoder.fit_transform(y)\n","X_bal, y_bal = ADASYN(random_state=42).fit_resample(X, y_encoded)\n","\n","# --- Train classifier ---\n","xgb_classifier = xgb.XGBClassifier(\n","    n_estimators=300, learning_rate=0.05, max_depth=10,\n","    subsample=0.9, colsample_bytree=0.9, scale_pos_weight=1,\n","    use_label_encoder=False, eval_metric='logloss', random_state=36\n",")\n","xgb_classifier.fit(X_bal, y_bal)\n","\n","# --- Prepare test data ---\n","test_df = pd.read_csv(test_csv_path)\n","test_df['Ids'] = test_df['Ids'].astype(str)\n","X_test = []\n","matched_ids = []\n","\n","for _, row in test_df.iterrows():\n","    fname = row['Ids'].split('.')[0]\n","    if fname in test_feature_dict:\n","        X_test.append(test_feature_dict[fname])\n","        matched_ids.append(row['Ids'])\n","\n","X_test = np.array(X_test)\n","y_test_pred = xgb_classifier.predict(X_test)\n","y_test_label = label_encoder.inverse_transform(y_test_pred)\n","\n","# --- Load or create result DataFrame ---\n","if os.path.exists(output_csv_path):\n","    result_df = pd.read_csv(output_csv_path)\n","else:\n","    result_df = pd.DataFrame({'Ids': matched_ids})\n","\n","# --- Merge new label predictions ---\n","new_label_df = pd.DataFrame({'Ids': matched_ids, LABEL_TO_PREDICT: y_test_label})\n","result_df = result_df.merge(new_label_df, on='Ids', how='outer')\n","\n","# --- Save final results ---\n","result_df.to_csv(output_csv_path, index=False)\n","print(f\"\\n✅ '{LABEL_TO_PREDICT}' predictions added to: {output_csv_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8i-DcTA9xQhG","executionInfo":{"status":"ok","timestamp":1753517549067,"user_tz":-330,"elapsed":160739,"user":{"displayName":"Kunal Goswami","userId":"06144718323032899612"}},"outputId":"fee365f7-3f33-4ee5-bf17-600f54712604"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:09:49] WARNING: /workspace/src/learner.cc:738: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  bst.update(dtrain, iteration=i, fobj=obj)\n"]},{"output_type":"stream","name":"stdout","text":["\n","✅ 'Vulgar' predictions added to: /content/drive/My Drive/Hasoc_Result-2025/Hindi_Predictions_Result_using_Resnet.csv\n"]}]},{"cell_type":"code","source":["#Sentiment\n","import os\n","import pickle\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder\n","from imblearn.over_sampling import ADASYN\n","import xgboost as xgb\n","\n","# ======= CONFIG ========\n","LABEL_TO_PREDICT = 'Sentiment'  # 🔁 Change this label for each run\n","train_feature_pkl = '/content/drive/MyDrive/Resnet_Method/Hindi_Image_Features_R101.pkl'\n","test_feature_pkl  = '/content/drive/MyDrive/Resnet_Method/Test_Hindi_Image_Features_R101.pkl'\n","train_csv_path    = '/content/drive/MyDrive/Datasets/HASOC-2025/Train/Hindi_train_2025/Hindi_train_data.csv'\n","test_csv_path     = '/content/drive/MyDrive/Datasets/HASOC-2025/Test/Hindi_test_2025/Hindi_test_data_wo_label.csv'\n","output_csv_path   = '/content/drive/My Drive/Hasoc_Result-2025/Hindi_Predictions_Result_using_Resnet.csv'\n","# =======================\n","\n","# --- Load features ---\n","with open(train_feature_pkl, 'rb') as f:\n","    train_feature_dict = pickle.load(f)\n","with open(test_feature_pkl, 'rb') as f:\n","    test_feature_dict = pickle.load(f)\n","\n","# --- Load labels ---\n","df = pd.read_csv(train_csv_path)\n","df['Ids'] = df['Ids'].astype(str)\n","df_filtered = df[df['Ids'].apply(lambda x: x.split('.')[0] in train_feature_dict)].copy()\n","\n","# --- Prepare training data for specific label ---\n","X, y = [], []\n","for _, row in df_filtered.iterrows():\n","    fname = row['Ids'].split('.')[0]\n","    X.append(train_feature_dict[fname])\n","    y.append(row[LABEL_TO_PREDICT])\n","\n","X = np.array(X)\n","y = np.array(y)\n","\n","# --- Encode and balance ---\n","label_encoder = LabelEncoder()\n","y_encoded = label_encoder.fit_transform(y)\n","X_bal, y_bal = ADASYN(random_state=42).fit_resample(X, y_encoded)\n","\n","# --- Train classifier ---\n","xgb_classifier = xgb.XGBClassifier(\n","    n_estimators=300, learning_rate=0.05, max_depth=10,\n","    subsample=0.9, colsample_bytree=0.9, scale_pos_weight=1,\n","    use_label_encoder=False, eval_metric='logloss', random_state=36\n",")\n","xgb_classifier.fit(X_bal, y_bal)\n","\n","# --- Prepare test data ---\n","test_df = pd.read_csv(test_csv_path)\n","test_df['Ids'] = test_df['Ids'].astype(str)\n","X_test = []\n","matched_ids = []\n","\n","for _, row in test_df.iterrows():\n","    fname = row['Ids'].split('.')[0]\n","    if fname in test_feature_dict:\n","        X_test.append(test_feature_dict[fname])\n","        matched_ids.append(row['Ids'])\n","\n","X_test = np.array(X_test)\n","y_test_pred = xgb_classifier.predict(X_test)\n","y_test_label = label_encoder.inverse_transform(y_test_pred)\n","\n","# --- Load or create result DataFrame ---\n","if os.path.exists(output_csv_path):\n","    result_df = pd.read_csv(output_csv_path)\n","else:\n","    result_df = pd.DataFrame({'Ids': matched_ids})\n","\n","# --- Merge new label predictions ---\n","new_label_df = pd.DataFrame({'Ids': matched_ids, LABEL_TO_PREDICT: y_test_label})\n","result_df = result_df.merge(new_label_df, on='Ids', how='outer')\n","\n","# --- Save final results ---\n","result_df.to_csv(output_csv_path, index=False)\n","print(f\"\\n✅ '{LABEL_TO_PREDICT}' predictions added to: {output_csv_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3N4mGOzPxQjz","executionInfo":{"status":"ok","timestamp":1753518166715,"user_tz":-330,"elapsed":617645,"user":{"displayName":"Kunal Goswami","userId":"06144718323032899612"}},"outputId":"d322f6e2-7a44-41fb-fb0a-d62c1fc0a218"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:12:30] WARNING: /workspace/src/learner.cc:738: \n","Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n","\n","  bst.update(dtrain, iteration=i, fobj=obj)\n"]},{"output_type":"stream","name":"stdout","text":["\n","✅ 'Sentiment' predictions added to: /content/drive/My Drive/Hasoc_Result-2025/Hindi_Predictions_Result_using_Resnet.csv\n"]}]},{"cell_type":"code","source":["#Target\n","import os\n","import pickle\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder\n","from imblearn.over_sampling import ADASYN\n","import xgboost as xgb\n","\n","# ======= CONFIG ========\n","LABEL_TO_PREDICT = 'Target'  # 🔁 Change this label for each run\n","train_feature_pkl = '/content/drive/MyDrive/Resnet_Method/Hindi_Image_Features_R101.pkl'\n","test_feature_pkl  = '/content/drive/MyDrive/Resnet_Method/Test_Hindi_Image_Features_R101.pkl'\n","train_csv_path    = '/content/drive/MyDrive/Datasets/HASOC-2025/Train/Hindi_train_2025/Hindi_train_data.csv'\n","test_csv_path     = '/content/drive/MyDrive/Datasets/HASOC-2025/Test/Hindi_test_2025/Hindi_test_data_wo_label.csv'\n","output_csv_path   = '/content/drive/My Drive/Hasoc_Result-2025/Hindi_Predictions_Result_using_Resnet.csv'\n","# =======================\n","\n","# --- Load features ---\n","with open(train_feature_pkl, 'rb') as f:\n","    train_feature_dict = pickle.load(f)\n","with open(test_feature_pkl, 'rb') as f:\n","    test_feature_dict = pickle.load(f)\n","\n","# --- Load labels ---\n","df = pd.read_csv(train_csv_path)\n","df['Ids'] = df['Ids'].astype(str)\n","df_filtered = df[df['Ids'].apply(lambda x: x.split('.')[0] in train_feature_dict)].copy()\n","\n","# --- Prepare training data for specific label ---\n","X, y = [], []\n","for _, row in df_filtered.iterrows():\n","    fname = row['Ids'].split('.')[0]\n","    X.append(train_feature_dict[fname])\n","    y.append(row[LABEL_TO_PREDICT])\n","\n","X = np.array(X)\n","y = np.array(y)\n","\n","# --- Encode and balance ---\n","label_encoder = LabelEncoder()\n","y_encoded = label_encoder.fit_transform(y)\n","X_bal, y_bal = ADASYN(random_state=42).fit_resample(X, y_encoded)\n","\n","# --- Train classifier ---\n","xgb_classifier = xgb.XGBClassifier(\n","    n_estimators=300, learning_rate=0.05, max_depth=10,\n","    subsample=0.9, colsample_bytree=0.9, scale_pos_weight=1,\n","    use_label_encoder=False, eval_metric='logloss', random_state=36\n",")\n","xgb_classifier.fit(X_bal, y_bal)\n","\n","# --- Prepare test data ---\n","test_df = pd.read_csv(test_csv_path)\n","test_df['Ids'] = test_df['Ids'].astype(str)\n","X_test = []\n","matched_ids = []\n","\n","for _, row in test_df.iterrows():\n","    fname = row['Ids'].split('.')[0]\n","    if fname in test_feature_dict:\n","        X_test.append(test_feature_dict[fname])\n","        matched_ids.append(row['Ids'])\n","\n","X_test = np.array(X_test)\n","y_test_pred = xgb_classifier.predict(X_test)\n","y_test_label = label_encoder.inverse_transform(y_test_pred)\n","\n","# --- Load or create result DataFrame ---\n","if os.path.exists(output_csv_path):\n","    result_df = pd.read_csv(output_csv_path)\n","else:\n","    result_df = pd.DataFrame({'Ids': matched_ids})\n","\n","# --- Merge new label predictions ---\n","new_label_df = pd.DataFrame({'Ids': matched_ids, LABEL_TO_PREDICT: y_test_label})\n","result_df = result_df.merge(new_label_df, on='Ids', how='outer')\n","\n","# --- Save final results ---\n","result_df.to_csv(output_csv_path, index=False)\n","print(f\"\\n✅ '{LABEL_TO_PREDICT}' predictions added to: {output_csv_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oGg4VirxxQnM","executionInfo":{"status":"ok","timestamp":1753519325631,"user_tz":-330,"elapsed":1158928,"user":{"displayName":"Kunal Goswami","userId":"06144718323032899612"}},"outputId":"473cf827-2f6f-4d34-fb66-284e77fcdf1b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:22:48] WARNING: /workspace/src/learner.cc:738: \n","Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n","\n","  bst.update(dtrain, iteration=i, fobj=obj)\n"]},{"output_type":"stream","name":"stdout","text":["\n","✅ 'Target' predictions added to: /content/drive/My Drive/Hasoc_Result-2025/Hindi_Predictions_Result_using_Resnet.csv\n"]}]},{"cell_type":"code","metadata":{"id":"1ee39b4b"},"source":["# Sentiment\n","\n","import pickle\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","from imblearn.over_sampling import ADASYN\n","import xgboost as xgb\n","\n","# ========== CONFIG ==========\n","train_feature_pkl = '/content/drive/MyDrive/Resnet_Method/Hindi_Image_Features_R101.pkl'\n","test_feature_pkl  = '/content/drive/MyDrive/Resnet_Method/Test_Hindi_Image_Features_R101.pkl'  # ⬅️ Pre-extracted test features\n","train_csv_path    = '/content/drive/MyDrive/Datasets/HASOC-2025/Train/Hindi_train_2025/Hindi_train_data.csv'\n","test_csv_path     = '/content/drive/MyDrive/Datasets/HASOC-2025/Test/Hindi_test_2025/Hindi_test_data_wo_label.csv'\n","# ============================\n","\n","# Load pre-extracted image features\n","with open(train_feature_pkl, 'rb') as f:\n","    train_feature_dict = pickle.load(f)\n","\n","with open(test_feature_pkl, 'rb') as f:\n","    test_feature_dict = pickle.load(f)\n","\n","# Load training labels\n","df = pd.read_csv(train_csv_path)\n","df['Ids'] = df['Ids'].astype(str)\n","\n","# Filter for matching training features\n","train_ids = set(train_feature_dict.keys())\n","df_filtered = df[df['Ids'].apply(lambda x: x.split('.')[0] in train_ids)].copy()\n","\n","# Prepare training data\n","X, y = [], []\n","for _, row in df_filtered.iterrows():\n","    fname = row['Ids'].split('.')[0]\n","    X.append(train_feature_dict[fname])\n","    y.append(row['Sentiment'])\n","\n","X = np.array(X)\n","y = np.array(y)\n","\n","# Encode class labels\n","label_encoder = LabelEncoder()\n","y_encoded = label_encoder.fit_transform(y)\n","\n","# Balance using ADASYN\n","adasyn = ADASYN(random_state=42)\n","X_bal, y_bal = adasyn.fit_resample(X, y_encoded)\n","\n","# Train XGBoost Classifier\n","xgb_classifier = xgb.XGBClassifier(\n","    n_estimators=300,\n","    learning_rate=0.05,\n","    max_depth=10,\n","    subsample=0.9,\n","    colsample_bytree=0.9,\n","    scale_pos_weight=1,\n","    use_label_encoder=False,\n","    eval_metric='logloss',\n","    random_state=36\n",")\n","\n","xgb_classifier.fit(X_bal, y_bal)\n","\n","# Load Test Metadata\n","test_df = pd.read_csv(test_csv_path)\n","test_df['Ids'] = test_df['Ids'].astype(str)\n","\n","# Match with test feature dictionary\n","X_test = []\n","matched_ids = []\n","\n","for _, row in test_df.iterrows():\n","    fname = row['Ids'].split('.')[0]\n","    if fname in test_feature_dict:\n","        X_test.append(test_feature_dict[fname])\n","        matched_ids.append(row['Ids'])\n","\n","X_test = np.array(X_test)\n","\n","# Predict\n","y_test_pred = xgb_classifier.predict(X_test)\n","y_test_label = label_encoder.inverse_transform(y_test_pred)\n","\n","# Prepare final DataFrame\n","result_df = pd.DataFrame({'Ids': matched_ids, 'Sentiment': y_test_label})\n","\n","# Save to Google Drive\n","output_path = '/content/drive/My Drive/Hasoc_Result-2025/Hindi_Predictions_Result_using_Resnet.csv'\n","result_df.to_csv(output_path, index=False)\n","print(f\"\\n✅ Predictions saved to: {output_path}\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Target\n","\n","import pickle\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","from imblearn.over_sampling import ADASYN\n","import xgboost as xgb\n","\n","# ========== CONFIG ==========\n","train_feature_pkl = '/content/drive/MyDrive/Resnet_Method/Hindi_Image_Features_R101.pkl'\n","test_feature_pkl  = '/content/drive/MyDrive/Resnet_Method/Test_Hindi_Image_Features_R101.pkl'  # ⬅️ Pre-extracted test features\n","train_csv_path    = '/content/drive/MyDrive/Datasets/HASOC-2025/Train/Hindi_train_2025/Hindi_train_data.csv'\n","test_csv_path     = '/content/drive/MyDrive/Datasets/HASOC-2025/Test/Hindi_test_2025/Hindi_test_data_wo_label.csv'\n","# ============================\n","\n","# Load pre-extracted image features\n","with open(train_feature_pkl, 'rb') as f:\n","    train_feature_dict = pickle.load(f)\n","\n","with open(test_feature_pkl, 'rb') as f:\n","    test_feature_dict = pickle.load(f)\n","\n","# Load training labels\n","df = pd.read_csv(train_csv_path)\n","df['Ids'] = df['Ids'].astype(str)\n","\n","# Filter for matching training features\n","train_ids = set(train_feature_dict.keys())\n","df_filtered = df[df['Ids'].apply(lambda x: x.split('.')[0] in train_ids)].copy()\n","\n","# Prepare training data\n","X, y = [], []\n","for _, row in df_filtered.iterrows():\n","    fname = row['Ids'].split('.')[0]\n","    X.append(train_feature_dict[fname])\n","    y.append(row['Target'])\n","\n","X = np.array(X)\n","y = np.array(y)\n","\n","# Encode class labels\n","label_encoder = LabelEncoder()\n","y_encoded = label_encoder.fit_transform(y)\n","\n","# Balance using ADASYN\n","adasyn = ADASYN(random_state=42)\n","X_bal, y_bal = adasyn.fit_resample(X, y_encoded)\n","\n","# Train XGBoost Classifier\n","xgb_classifier = xgb.XGBClassifier(\n","    n_estimators=300,\n","    learning_rate=0.05,\n","    max_depth=10,\n","    subsample=0.9,\n","    colsample_bytree=0.9,\n","    scale_pos_weight=1,\n","    use_label_encoder=False,\n","    eval_metric='logloss',\n","    random_state=36\n",")\n","\n","xgb_classifier.fit(X_bal, y_bal)\n","\n","# Load Test Metadata\n","test_df = pd.read_csv(test_csv_path)\n","test_df['Ids'] = test_df['Ids'].astype(str)\n","\n","# Match with test feature dictionary\n","X_test = []\n","matched_ids = []\n","\n","for _, row in test_df.iterrows():\n","    fname = row['Ids'].split('.')[0]\n","    if fname in test_feature_dict:\n","        X_test.append(test_feature_dict[fname])\n","        matched_ids.append(row['Ids'])\n","\n","X_test = np.array(X_test)\n","\n","# Predict\n","y_test_pred = xgb_classifier.predict(X_test)\n","y_test_label = label_encoder.inverse_transform(y_test_pred)\n","\n","# Prepare final DataFrame\n","result_df = pd.DataFrame({'Ids': matched_ids, 'Target': y_test_label})\n","\n","# Save to Google Drive\n","output_path = '/content/drive/My Drive/Hasoc_Result-2025/Hindi_Predictions_Result_using_Resnet.csv'\n","result_df.to_csv(output_path, index=False)\n","print(f\"\\n✅ Predictions saved to: {output_path}\")\n"],"metadata":{"id":"47PJYnllufna"},"execution_count":null,"outputs":[]}]}