{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOIUJiGCUJTd5g3CpyxD2qy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J1vuOattqIgG","executionInfo":{"status":"ok","timestamp":1753104703822,"user_tz":-330,"elapsed":4321,"user":{"displayName":"Subham Rai","userId":"06576043812723112607"}},"outputId":"f1f9b63f-cb88-4c34-ef6c-85247f38a876"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"9mnl80ovokbW","executionInfo":{"status":"ok","timestamp":1753104708771,"user_tz":-330,"elapsed":151,"user":{"displayName":"Subham Rai","userId":"06576043812723112607"}},"outputId":"b52938c8-19a6-4728-bbc7-e802ec7cffd7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                  Ids                                                OCR\n","0  image_ben_1422.png  বৌ-এর প্রেগনেন্সি রিপোর্ট পজিটিভ জানার পর বর চ...\n","1  image_ben_3908.jpg                                 কিন্তু মিষ্টতা নেই\n","2  image_ben_4634.jpg   মানুষ যা দেখে প্রথম সিঙারা আবিষ্কারের ধারণা পায় \n","3  image_ben_3192.png  এক মেয়ে ফ্যানে ওড়না পাচিয়ে সুই*সাইড করতে যাচ্ছ...\n","4  image_ben_4836.jpg                                   No text detected"],"text/html":["\n","  <div id=\"df-53ddbe4f-b99c-4bdd-993e-de126b8f9ec5\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Ids</th>\n","      <th>OCR</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>image_ben_1422.png</td>\n","      <td>বৌ-এর প্রেগনেন্সি রিপোর্ট পজিটিভ জানার পর বর চ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>image_ben_3908.jpg</td>\n","      <td>কিন্তু মিষ্টতা নেই</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>image_ben_4634.jpg</td>\n","      <td>মানুষ যা দেখে প্রথম সিঙারা আবিষ্কারের ধারণা পায়</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>image_ben_3192.png</td>\n","      <td>এক মেয়ে ফ্যানে ওড়না পাচিয়ে সুই*সাইড করতে যাচ্ছ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>image_ben_4836.jpg</td>\n","      <td>No text detected</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-53ddbe4f-b99c-4bdd-993e-de126b8f9ec5')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-53ddbe4f-b99c-4bdd-993e-de126b8f9ec5 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-53ddbe4f-b99c-4bdd-993e-de126b8f9ec5');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-3261b4aa-abf5-4bac-98e0-9fef91f9e721\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3261b4aa-abf5-4bac-98e0-9fef91f9e721')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-3261b4aa-abf5-4bac-98e0-9fef91f9e721 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"test_df","summary":"{\n  \"name\": \"test_df\",\n  \"rows\": 1821,\n  \"fields\": [\n    {\n      \"column\": \"Ids\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1821,\n        \"samples\": [\n          \"image_ben_1694.png\",\n          \"image_ben_7418.jpg\",\n          \"image_ben_3496.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OCR\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1688,\n        \"samples\": [\n          \"\\u09aa\\u09cd\\u09b0\\u09a5\\u09ae\\u09ac\\u09be\\u09b0 \\u099b\\u09c7\\u0995\\u09be \\u0996\\u09be\\u0993\\u09df\\u09be \\u09af\\u0996\\u09a8 \\u099c\\u09bf\\u099c\\u09cd\\u099e\\u09c7\\u09b8 \\u0995\\u09b0\\u09cb \\u09ac\\u09b9\\u09cd\\u09a7\\u0987\\u09b8\\u09c7 \\u09b8\\u09ac \\u09a0\\u09bf\\u0995 \\u09a4\\u09cb? ... . \\u09ac\\u09a8\\u09cd\\u09a7\\u09c1 :-\",\n          \"\\u09ac\\u09be\\u09a8\\u09cd\\u09a7\\u09ac\\u09c0\\u09b0 \\u09b8\\u0999\\u09cd\\u0997\\u09c7 \\u0985\\u09a8\\u09c7\\u0995 \\u09a6\\u09bf\\u09a8 \\u09aa\\u09c7\\u09b0\\u09c7 \\u09a6\\u09c7\\u0996\\u09be \\u09b9\\u09b2\\u09cb \\u09ae\\u09c7\\u09df\\u09c7\\u09b0\\u09be \\u09af\\u09be \\u0995\\u09b0\\u09c7 \\u0986\\u09b0 \\u099b\\u09c7\\u09b2\\u09c7\\u09b0\\u09be \\u09af\\u09be \\u0995\\u09b0\\u09c7\",\n          \"AJ KKR jitla Ami nunu kete fele dibo Abar challenge dilam\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":31}],"source":["import pandas as pd\n","test_path='/content/drive/MyDrive/Colab Notebooks/Bangla_new/bengali_test_data_wo_label.csv'\n","test_df=pd.read_csv(test_path)\n","test_df.head()"]},{"cell_type":"code","source":["import pandas as pd\n","path='/content/drive/MyDrive/Colab Notebooks/Bangla_new/Bangla_train_data_enriched.csv'\n","df=pd.read_csv(path)\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":382},"id":"bTPXwv3x40on","executionInfo":{"status":"ok","timestamp":1753104711560,"user_tz":-330,"elapsed":694,"user":{"displayName":"Subham Rai","userId":"06576043812723112607"}},"outputId":"71c2e4b7-d8d2-4512-cfc3-c5aa58bd99c8"},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                  Ids Sentiment    Sarcasm      Vulgar    Abuse  Target  \\\n","0  image_ben_3635.jpg   Neutral  Sarcastic  Non Vulgar  Abusive  Gender   \n","1  image_ben_1586.png  Negative  Sarcastic  Non Vulgar  Abusive  Gender   \n","2  image_ben_4040.jpg  Negative  Sarcastic  Non Vulgar  Abusive  Gender   \n","3  image_ben_5074.jpg   Neutral  Sarcastic  Non Vulgar  Abusive  Gender   \n","4  image_ben_7351.jpg  Negative  Sarcastic      Vulgar  Abusive  Gender   \n","\n","                              extracted_bengali_text  \\\n","0  1 1 ! `ে বজন'  ঙঙব 2হ; ত.৫:হ9 ৫োহ_ য  3৫ঙ 16 3...   \n","1  ^আহভ ৯ ী  জষ৮=শ 11 [২ঃম|হসর9 ও0$, ৫ঁ| |@ আব শহ...   \n","2  মাজানো-পাশের বাড়ির চুলবুলি আমার থেকে রেশিঅক্স...   \n","3  ৫$ কে ফিঙ্গারং করে দেওয়ার পর যখন সে চরমসুখ অনু...   \n","4  পটিপতে টিপতে যখন ব্যাথ্যা অনুভবহয় ূ০)চ]}৫]] 0...   \n","\n","                             translated_english_text  \\\n","0  1 1! `` `Bajan '' is 2 h; T.1: Yes 9 ৰ ৰ - 3g ...   \n","1  ^Ahh ৰ ৰ ৰ ৰ ৰ ৰ ৰ ৰ ৮ ৮ 11 [2 mm | Husar 9 & ...   \n","2  Majano-palace house haircuts are getting $ 5xg...   \n","3  After fingering $ 5, when he feels a pig, a pi...   \n","4  When pressing on the pottip, when the pain is ...   \n","\n","                               translated_hindi_text  \n","0  11! `` `बाजन '' 2 घंटे है; T.1: YES 9 ৰ ৰ - 3G...  \n","1  ^Ahh ৰ ৰ ৰ ৰ ৰ ৰ ৰ ৮ ৮ ৮ ৮ 11 [2 मिमी | हुसार ...  \n","2  माजानो-पालस हाउस हेयरकट्स मुझसे $ 5xgen प्राप्...  \n","3  $ 5 की छलाकन के बाद, जब वह एक सुअर, एक सुअर मह...  \n","4  जब पोटिप पर दबाया जाता है, जब दर्द 1) f]}} 1] ...  "],"text/html":["\n","  <div id=\"df-db25c00e-3b4b-48be-add2-7c2d7bbbcce3\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Ids</th>\n","      <th>Sentiment</th>\n","      <th>Sarcasm</th>\n","      <th>Vulgar</th>\n","      <th>Abuse</th>\n","      <th>Target</th>\n","      <th>extracted_bengali_text</th>\n","      <th>translated_english_text</th>\n","      <th>translated_hindi_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>image_ben_3635.jpg</td>\n","      <td>Neutral</td>\n","      <td>Sarcastic</td>\n","      <td>Non Vulgar</td>\n","      <td>Abusive</td>\n","      <td>Gender</td>\n","      <td>1 1 ! `ে বজন'  ঙঙব 2হ; ত.৫:হ9 ৫োহ_ য  3৫ঙ 16 3...</td>\n","      <td>1 1! `` `Bajan '' is 2 h; T.1: Yes 9 ৰ ৰ - 3g ...</td>\n","      <td>11! `` `बाजन '' 2 घंटे है; T.1: YES 9 ৰ ৰ - 3G...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>image_ben_1586.png</td>\n","      <td>Negative</td>\n","      <td>Sarcastic</td>\n","      <td>Non Vulgar</td>\n","      <td>Abusive</td>\n","      <td>Gender</td>\n","      <td>^আহভ ৯ ী  জষ৮=শ 11 [২ঃম|হসর9 ও0$, ৫ঁ| |@ আব শহ...</td>\n","      <td>^Ahh ৰ ৰ ৰ ৰ ৰ ৰ ৰ ৰ ৮ ৮ 11 [2 mm | Husar 9 &amp; ...</td>\n","      <td>^Ahh ৰ ৰ ৰ ৰ ৰ ৰ ৰ ৮ ৮ ৮ ৮ 11 [2 मिमी | हुसार ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>image_ben_4040.jpg</td>\n","      <td>Negative</td>\n","      <td>Sarcastic</td>\n","      <td>Non Vulgar</td>\n","      <td>Abusive</td>\n","      <td>Gender</td>\n","      <td>মাজানো-পাশের বাড়ির চুলবুলি আমার থেকে রেশিঅক্স...</td>\n","      <td>Majano-palace house haircuts are getting $ 5xg...</td>\n","      <td>माजानो-पालस हाउस हेयरकट्स मुझसे $ 5xgen प्राप्...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>image_ben_5074.jpg</td>\n","      <td>Neutral</td>\n","      <td>Sarcastic</td>\n","      <td>Non Vulgar</td>\n","      <td>Abusive</td>\n","      <td>Gender</td>\n","      <td>৫$ কে ফিঙ্গারং করে দেওয়ার পর যখন সে চরমসুখ অনু...</td>\n","      <td>After fingering $ 5, when he feels a pig, a pi...</td>\n","      <td>$ 5 की छलाकन के बाद, जब वह एक सुअर, एक सुअर मह...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>image_ben_7351.jpg</td>\n","      <td>Negative</td>\n","      <td>Sarcastic</td>\n","      <td>Vulgar</td>\n","      <td>Abusive</td>\n","      <td>Gender</td>\n","      <td>পটিপতে টিপতে যখন ব্যাথ্যা অনুভবহয় ূ০)চ]}৫]] 0...</td>\n","      <td>When pressing on the pottip, when the pain is ...</td>\n","      <td>जब पोटिप पर दबाया जाता है, जब दर्द 1) f]}} 1] ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-db25c00e-3b4b-48be-add2-7c2d7bbbcce3')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-db25c00e-3b4b-48be-add2-7c2d7bbbcce3 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-db25c00e-3b4b-48be-add2-7c2d7bbbcce3');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-f273317e-dcfb-41f3-ad18-ba7ed8e0231c\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f273317e-dcfb-41f3-ad18-ba7ed8e0231c')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-f273317e-dcfb-41f3-ad18-ba7ed8e0231c button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 2693,\n  \"fields\": [\n    {\n      \"column\": \"Ids\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2693,\n        \"samples\": [\n          \"image_ben_1391.png\",\n          \"image_ben_1571.png\",\n          \"image_ben_3954.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Neutral\",\n          \"Negative\",\n          \"Positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sarcasm\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Non-Sarcastic\",\n          \"Sarcastic\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Vulgar\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Vulgar\",\n          \"Non Vulgar\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Abuse\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Non-abusive\",\n          \"Abusive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Target\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 32,\n        \"samples\": [\n          \"Individual, Social Sub-groups\",\n          \"National Origin\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"extracted_bengali_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2577,\n        \"samples\": [\n          \"\\u09af\\u0996\\u09a8 \\u09ac\\u09c1\\u099d\\u09a4\\u09c7 \\u09aa\\u09be\\u09b0\\u09cb \\u098f\\u09ac\\u09be\\u09b0 \\u09b6\\u09cd\\u09b0\\u09be\\u09ac\\u09a8\\u09cd\\u09a4\\u09c0 \\u09ac\\u09c1\\u0995\\u09c7\\u09b0 \\u0989\\u09aa\\u09b0 \\u09aa\\u09be \\u09a4\\u09c1\\u09b2\\u09ac\\u09c7\",\n          \"\\u09eb\\u09e9? \\u098f\\u09b0\\u0995\\u09ae \\u09ec0\\u098b \\u0993\\u0995\\u09c7 \\u0996\\u09b6\\u09b6\\u09ef\\u0983\\u09ef \\u09a5\\u09be\\u0995\\u09a4\\u09c7 \\u09b9\\u09ac\\u09c7 \\u0997\\u09ef'\\u0964\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"translated_english_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2565,\n        \"samples\": [\n          \"\\\"Rely on the Neev\\\" \\\"\\u09f0 4 Char Ho\\\" (7] || Abrar 4 $? 8 ++ 122+| f.\",\n          \"$ 0] Ogok da 0 [Don't get up at night\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"translated_hindi_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2554,\n        \"samples\": [\n          \"\\u091c\\u092c \\u0909\\u0938\\u0947 \\u0905\\u0902\\u0924 \\u092e\\u0947\\u0902 \\u092a\\u0924\\u093e \\u091a\\u0932\\u0924\\u093e \\u0939\\u0948 \\u0915\\u093f \\u0915\\u094b\\u0908 \\u092d\\u0940 \\u0932\\u0921\\u093c\\u0915\\u0940 \\u0916\\u0924\\u0930\\u0947 \\u092e\\u0947\\u0902 \\u0939\\u0948 \\u0924\\u094b \\u0915\\u094b\\u0908 \\u092d\\u0940 \\u0932\\u0921\\u093c\\u0915\\u0940 \\u0928\\u0939\\u0940\\u0902 \\u0939\\u094b\\u0917\\u0940\",\n          \"\\u0924\\u0941\\u092e \\u092e\\u0947\\u0930\\u0947 \\u0936\\u0930\\u0940\\u0930 \\u092a\\u0930 \\u092e\\u0947\\u0930\\u0947 \\u0936\\u0930\\u0940\\u0930 \\u0939\\u094b\\u0964\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","path_1='/content/drive/MyDrive/Colab Notebooks/Bangla_new/Bangla_train_image_features.pkl'\n","Img_Feature=pd.read_pickle(path_1)\n","# Assuming Img_Feature is a dictionary with image IDs as keys and features as values\n","# Extract image features in the order of df['Ids']\n","Img_feature=np.array([Img_Feature[img_id] for img_id in df['Ids']])\n","X1=Img_feature\n","X1.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RHzjgwQ84VPp","executionInfo":{"status":"ok","timestamp":1753104715165,"user_tz":-330,"elapsed":1069,"user":{"displayName":"Subham Rai","userId":"06576043812723112607"}},"outputId":"b9021951-be5f-405f-a2c6-acb37cdc7dcb"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2693, 4096)"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["path_2='/content/drive/MyDrive/Colab Notebooks/Bangla_new/Bangla_train_ocr_features_word2vec.pkl'\n","\n","# Load the text features (assuming it's a numpy array)\n","import pickle\n","with open(path_2, 'rb') as f:\n","    Ocr_feature = pickle.load(f)\n","\n","# Assume the order of samples in Ocr_feature corresponds to the order of 'Ids' in df\n","# Select the first len(df) rows to align with the training data\n","Ocr_feature = Ocr_feature[:len(df)]\n","\n","X2 = Ocr_feature\n","X2.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yKQtQg5x4VSQ","executionInfo":{"status":"ok","timestamp":1753104716911,"user_tz":-330,"elapsed":38,"user":{"displayName":"Subham Rai","userId":"06576043812723112607"}},"outputId":"e1ec7844-a193-40c5-d61d-70dc9c60c5d3"},"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2693, 100)"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["import pickle\n","import pandas as pd # Import pandas\n","import numpy as np # Import numpy\n","\n","with open('/content/drive/MyDrive/Colab Notebooks/Bangla_new/Bangla_test_ocr_features_word2vec.pkl', 'rb') as f:\n","    X_text_test = pickle.load(f)\n","\n","with open('/content/drive/MyDrive/Colab Notebooks/Bangla_new/Bangla_test_image_features.pkl', 'rb') as f:\n","    Img_Feature_test = pickle.load(f)\n","\n","# Assuming Img_Feature_test is a dictionary with image IDs as keys and features as values\n","# Extract image features in the order of test_df['Ids']\n","X_image_test = np.array([Img_Feature_test[img_id] for img_id in test_df['Ids']])\n","\n","\n","# Truncate X_text_test and X_image_test to match the number of samples in test_df\n","X_text_test = X_text_test[:len(test_df)]\n","# X_image_test is already aligned with test_df['Ids'], so no truncation needed here\n","\n","\n","print(\"Shape of X_text_test after truncation:\", X_text_test.shape)\n","print(\"Shape of X_image_test:\", X_image_test.shape)"],"metadata":{"id":"5FfsdZkC6mMA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753104719332,"user_tz":-330,"elapsed":208,"user":{"displayName":"Subham Rai","userId":"06576043812723112607"}},"outputId":"f7032d3b-44e1-448d-9f7b-5de4dc4b83b7"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of X_text_test after truncation: (1821, 100)\n","Shape of X_image_test: (1821, 4096)\n"]}]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","# Create separate scalers for image and text features\n","scaler_image = StandardScaler()\n","scaler_text = StandardScaler()\n","\n","# Fit the scalers on the training data\n","X1= scaler_image.fit_transform(X1)\n","X2 = scaler_text.fit_transform(X2)\n","\n","\n","# Scale the test data using the fitted scalers\n","X_text_test_scaled = scaler_text.transform(X_text_test)\n","X_image_test_scaled = scaler_image.transform(X_image_test)"],"metadata":{"id":"kVJP07fI4qMo","executionInfo":{"status":"ok","timestamp":1753104722142,"user_tz":-330,"elapsed":296,"user":{"displayName":"Subham Rai","userId":"06576043812723112607"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["#Sentiment\n","import numpy as np\n","import pandas as pd\n","\n","from sklearn.utils import class_weight\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","\n","import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Dense, Dropout, Concatenate, BatchNormalization\n","\n","# ----------------------------\n","# STEP 1: Prepare Labels\n","# ----------------------------\n","from sklearn.preprocessing import LabelEncoder\n","le = LabelEncoder()\n","y = le.fit_transform(df['Sentiment'])  # Multiclass labels\n","print(df['Sentiment'].value_counts())\n","num_classes = len(np.unique(y))\n","\n","# ----------------------------\n","# STEP 2: Build the Model\n","# ----------------------------\n","\n","# 1. Text Branch\n","text_input = Input(shape=(X2.shape[1],), name='text_input')\n","text_branch = Dense(512, activation='relu')(text_input)\n","text_branch = BatchNormalization()(text_branch)\n","text_branch = Dropout(0.2)(text_branch)\n","text_branch = Dense(256, activation='relu')(text_branch)\n","text_branch = BatchNormalization()(text_branch)\n","text_branch = Dropout(0.2)(text_branch)\n","\n","# 2. Image Branch\n","image_input = Input(shape=(X1.shape[1],), name='image_input')\n","image_branch = Dense(512, activation='relu')(image_input)\n","image_branch = BatchNormalization()(image_branch)\n","image_branch = Dropout(0.2)(image_branch)\n","image_branch = Dense(256, activation='relu')(image_branch)\n","image_branch = BatchNormalization()(image_branch)\n","image_branch = Dropout(0.2)(image_branch)\n","\n","# 3. Merge Modalities\n","combined = Concatenate()([text_branch, image_branch])\n","combined = Dense(512, activation='relu')(combined)\n","combined = BatchNormalization()(combined)\n","combined = Dropout(0.2)(combined)\n","combined = Dense(256, activation='relu')(combined)\n","combined = BatchNormalization()(combined)\n","combined = Dropout(0.2)(combined)\n","combined = Dense(128, activation='relu')(combined)\n","combined = BatchNormalization()(combined)\n","combined = Dropout(0.2)(combined)\n","combined = Dense(64, activation='relu')(combined)\n","combined = BatchNormalization()(combined)\n","combined = Dropout(0.2)(combined)\n","\n","\n","# 4. Output Layer (multiclass)\n","output = Dense(num_classes, activation='softmax')(combined)\n","\n","# 5. Model\n","model = Model(inputs=[text_input, image_input], outputs=output)\n","\n","# 6. Compile\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","# 7. Class Weights\n","class_weights = class_weight.compute_class_weight(class_weight='balanced',\n","                                                  classes=np.unique(y),\n","                                                  y=y.tolist())\n","class_weights = dict(enumerate(class_weights))\n","\n","# 8. Train\n","history = model.fit([X2, X1], y,\n","                    batch_size=16,\n","                    epochs=50,\n","                    class_weight=class_weights)\n","\n","# ----------------------------\n","# STEP 4: Predict on Separate Test Dataset\n","# ----------------------------\n","\n","pred_probs = model.predict([X_text_test_scaled, X_image_test_scaled])\n","pred_labels = np.argmax(pred_probs, axis=1)\n","\n","pred_names = le.inverse_transform(pred_labels)\n","test_df['Sentiment'] = pred_names\n","\n","# ----------------------------\n","# STEP 5: Save Predictions to Google Drive\n","# ----------------------------\n","#from google.colab import drive\n","#drive.mount('/content/drive')\n","\n","output_path = '/content/drive/MyDrive/Colab Notebooks/Bangla_new/Bangla_Predictions_Result.csv'\n","test_df.to_csv(output_path, index=False)\n","print(f\"✅ Sentiment predictions saved to: {output_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"_8PfuG55d-Ae","executionInfo":{"status":"ok","timestamp":1753105213662,"user_tz":-330,"elapsed":489155,"user":{"displayName":"Subham Rai","userId":"06576043812723112607"}},"outputId":"dd554b74-a20c-41fe-e56f-302cde4d7ce6"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Sentiment\n","Negative    1476\n","Positive     906\n","Neutral      311\n","Name: count, dtype: int64\n","Epoch 1/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 51ms/step - accuracy: 0.3486 - loss: 1.5334\n","Epoch 2/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.3452 - loss: 1.2090\n","Epoch 3/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 52ms/step - accuracy: 0.4285 - loss: 1.1126\n","Epoch 4/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.4651 - loss: 1.0550\n","Epoch 5/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - accuracy: 0.5039 - loss: 0.9421\n","Epoch 6/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 48ms/step - accuracy: 0.5993 - loss: 0.8023\n","Epoch 7/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 53ms/step - accuracy: 0.6536 - loss: 0.7264\n","Epoch 8/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.6901 - loss: 0.6273\n","Epoch 9/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 45ms/step - accuracy: 0.7414 - loss: 0.5622\n","Epoch 10/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 52ms/step - accuracy: 0.8092 - loss: 0.4338\n","Epoch 11/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.8368 - loss: 0.3817\n","Epoch 12/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - accuracy: 0.8339 - loss: 0.3983\n","Epoch 13/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 47ms/step - accuracy: 0.8403 - loss: 0.3840\n","Epoch 14/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.8409 - loss: 0.3802\n","Epoch 15/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 42ms/step - accuracy: 0.8747 - loss: 0.3069\n","Epoch 16/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.9049 - loss: 0.2176\n","Epoch 17/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.8860 - loss: 0.2614\n","Epoch 18/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step - accuracy: 0.8978 - loss: 0.2470\n","Epoch 19/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - accuracy: 0.9097 - loss: 0.2064\n","Epoch 20/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 52ms/step - accuracy: 0.9115 - loss: 0.2083\n","Epoch 21/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.8969 - loss: 0.2553\n","Epoch 22/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - accuracy: 0.9049 - loss: 0.2295\n","Epoch 23/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - accuracy: 0.9173 - loss: 0.2022\n","Epoch 24/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.9133 - loss: 0.2072\n","Epoch 25/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 52ms/step - accuracy: 0.9345 - loss: 0.1648\n","Epoch 26/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.9199 - loss: 0.2251\n","Epoch 27/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 45ms/step - accuracy: 0.9310 - loss: 0.1702\n","Epoch 28/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - accuracy: 0.9458 - loss: 0.1344\n","Epoch 29/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 48ms/step - accuracy: 0.9298 - loss: 0.2019\n","Epoch 30/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.9427 - loss: 0.1455\n","Epoch 31/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.9371 - loss: 0.1560\n","Epoch 32/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 46ms/step - accuracy: 0.9351 - loss: 0.1636\n","Epoch 33/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 45ms/step - accuracy: 0.9431 - loss: 0.1335\n","Epoch 34/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 49ms/step - accuracy: 0.9545 - loss: 0.1219\n","Epoch 35/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - accuracy: 0.9376 - loss: 0.1508\n","Epoch 36/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 44ms/step - accuracy: 0.9213 - loss: 0.2078\n","Epoch 37/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 47ms/step - accuracy: 0.9214 - loss: 0.2063\n","Epoch 38/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.9446 - loss: 0.1346\n","Epoch 39/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.9533 - loss: 0.1078\n","Epoch 40/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 45ms/step - accuracy: 0.9531 - loss: 0.1242\n","Epoch 41/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - accuracy: 0.9589 - loss: 0.1166\n","Epoch 42/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.9634 - loss: 0.0889\n","Epoch 43/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - accuracy: 0.9573 - loss: 0.1061\n","Epoch 44/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 53ms/step - accuracy: 0.9322 - loss: 0.1737\n","Epoch 45/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - accuracy: 0.9559 - loss: 0.1126\n","Epoch 46/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step - accuracy: 0.9495 - loss: 0.1276\n","Epoch 47/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 49ms/step - accuracy: 0.9562 - loss: 0.1085\n","Epoch 48/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.9316 - loss: 0.1949\n","Epoch 49/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.9315 - loss: 0.1566\n","Epoch 50/50\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - accuracy: 0.9440 - loss: 0.1479\n","\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n","✅ Sentiment predictions saved to: /content/drive/MyDrive/Colab Notebooks/Bangla_new/Bangla_Predictions_Result.csv\n"]}]},{"cell_type":"code","source":["# Sarcasm\n","\n","import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.utils import class_weight\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","\n","import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Dense, Dropout, Concatenate, BatchNormalization\n","\n","# ----------------------------\n","# STEP 1: Prepare Labels\n","# ----------------------------\n","le = LabelEncoder()\n","y = le.fit_transform(df['Sarcasm'])  # df is the training DataFrame\n","print('Training label distribution:', pd.Series(y).value_counts())\n","\n","# ----------------------------\n","# STEP 2: Build the Model\n","# ----------------------------\n","\n","# 1. Text Branch\n","text_input = Input(shape=(X2.shape[1],), name='text_input')\n","text_branch = Dense(512, activation='relu')(text_input)\n","text_branch = BatchNormalization()(text_branch)\n","text_branch = Dropout(0.2)(text_branch)\n","text_branch = Dense(256, activation='relu')(text_branch)\n","text_branch = BatchNormalization()(text_branch)\n","text_branch = Dropout(0.2)(text_branch)\n","\n","# 2. Image Branch\n","image_input = Input(shape=(X1.shape[1],), name='image_input')\n","image_branch = Dense(512, activation='relu')(image_input)\n","image_branch = BatchNormalization()(image_branch)\n","image_branch = Dropout(0.2)(image_branch)\n","image_branch = Dense(256, activation='relu')(image_branch)\n","image_branch = BatchNormalization()(image_branch)\n","image_branch = Dropout(0.2)(image_branch)\n","\n","# 3. Merge Modalities\n","combined = Concatenate()([text_branch, image_branch])\n","combined = Dense(512, activation='relu')(combined)\n","combined = BatchNormalization()(combined)\n","combined = Dropout(0.2)(combined)\n","combined = Dense(256, activation='relu')(combined)\n","combined = BatchNormalization()(combined)\n","combined = Dropout(0.2)(combined)\n","combined = Dense(128, activation='relu')(combined)\n","combined = BatchNormalization()(combined)\n","combined = Dropout(0.2)(combined)\n","combined = Dense(64, activation='relu')(combined)\n","combined = BatchNormalization()(combined)\n","combined = Dropout(0.2)(combined)\n","\n","# 4. Output Layer\n","output = Dense(1, activation='sigmoid')(combined)\n","model = Model(inputs=[text_input, image_input], outputs=output)\n","\n","# ----------------------------\n","# STEP 3: Compile and Train\n","# ----------------------------\n","\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Class Weights\n","class_weights = class_weight.compute_class_weight(\n","    class_weight='balanced',\n","    classes=np.unique(y),\n","    y=y\n",")\n","class_weights = dict(enumerate(class_weights))\n","\n","# Train on full training data (no split)\n","history = model.fit([X2, X1], y,\n","                    batch_size=16,\n","                    epochs=100,\n","                    class_weight=class_weights)\n","\n","# ----------------------------\n","# STEP 4: Predict on Separate Test Dataset\n","# ----------------------------\n","\n","\n","y_pred_probs = model.predict([X_text_test_scaled, X_image_test_scaled]) # Corrected typo\n","y_pred_labels = (y_pred_probs > 0.5).astype(int).flatten()\n","\n","mapped_labels = ['Sarcastic' if label == 1 else 'Non-Sarcastic' for label in y_pred_labels]\n","\n","test_df['Sarcasm']=mapped_labels\n","\n","# ----------------------------\n","# STEP 5: Save to Google Drive\n","# ----------------------------\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","output_path = '/content/drive/MyDrive/Colab Notebooks/Bangla_new/Bangla_Predictions_Result.csv'\n","test_df.to_csv(output_path, index=False)\n","print(f\"✅ Predictions saved to: {output_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"x-YZu5LkT3Cv","executionInfo":{"status":"ok","timestamp":1753106177502,"user_tz":-330,"elapsed":939991,"user":{"displayName":"Subham Rai","userId":"06576043812723112607"}},"outputId":"9f2406d5-4bd2-47c7-b37a-e4ff5a58e7ad"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Training label distribution: 1    2081\n","0     612\n","Name: count, dtype: int64\n","Epoch 1/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 45ms/step - accuracy: 0.5118 - loss: 0.8402\n","Epoch 2/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.5306 - loss: 0.7373\n","Epoch 3/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.5845 - loss: 0.6835\n","Epoch 4/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.6364 - loss: 0.6296\n","Epoch 5/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 52ms/step - accuracy: 0.7095 - loss: 0.5275\n","Epoch 6/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.7940 - loss: 0.4296\n","Epoch 7/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 47ms/step - accuracy: 0.8359 - loss: 0.3604\n","Epoch 8/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 53ms/step - accuracy: 0.8784 - loss: 0.2782\n","Epoch 9/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 49ms/step - accuracy: 0.8761 - loss: 0.2932\n","Epoch 10/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9067 - loss: 0.2482\n","Epoch 11/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 52ms/step - accuracy: 0.9102 - loss: 0.2095\n","Epoch 12/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 48ms/step - accuracy: 0.9272 - loss: 0.1849\n","Epoch 13/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.9092 - loss: 0.2351\n","Epoch 14/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - accuracy: 0.9370 - loss: 0.1560\n","Epoch 15/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 44ms/step - accuracy: 0.9348 - loss: 0.1491\n","Epoch 16/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.9431 - loss: 0.1601\n","Epoch 17/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9498 - loss: 0.1423\n","Epoch 18/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 50ms/step - accuracy: 0.9593 - loss: 0.1059\n","Epoch 19/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 53ms/step - accuracy: 0.9410 - loss: 0.1411\n","Epoch 20/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.9553 - loss: 0.1121\n","Epoch 21/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - accuracy: 0.9477 - loss: 0.1328\n","Epoch 22/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - accuracy: 0.9350 - loss: 0.1638\n","Epoch 23/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - accuracy: 0.9534 - loss: 0.1212\n","Epoch 24/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - accuracy: 0.9596 - loss: 0.1128\n","Epoch 25/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 48ms/step - accuracy: 0.9624 - loss: 0.1093\n","Epoch 26/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - accuracy: 0.9587 - loss: 0.1036\n","Epoch 27/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.9620 - loss: 0.0850\n","Epoch 28/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.9489 - loss: 0.1285\n","Epoch 29/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - accuracy: 0.9735 - loss: 0.0752\n","Epoch 30/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - accuracy: 0.9541 - loss: 0.1159\n","Epoch 31/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step - accuracy: 0.9695 - loss: 0.0873\n","Epoch 32/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 49ms/step - accuracy: 0.9582 - loss: 0.1034\n","Epoch 33/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.9662 - loss: 0.0803\n","Epoch 34/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step - accuracy: 0.9721 - loss: 0.0868\n","Epoch 35/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.9713 - loss: 0.0721\n","Epoch 36/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.9673 - loss: 0.1092\n","Epoch 37/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9768 - loss: 0.0645\n","Epoch 38/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.9510 - loss: 0.1111\n","Epoch 39/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.9660 - loss: 0.0986\n","Epoch 40/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 54ms/step - accuracy: 0.9778 - loss: 0.0735\n","Epoch 41/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 55ms/step - accuracy: 0.9765 - loss: 0.0820\n","Epoch 42/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.9636 - loss: 0.0836\n","Epoch 43/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 49ms/step - accuracy: 0.9739 - loss: 0.0765\n","Epoch 44/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.9616 - loss: 0.0871\n","Epoch 45/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 48ms/step - accuracy: 0.9742 - loss: 0.0514\n","Epoch 46/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.9859 - loss: 0.0366\n","Epoch 47/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 52ms/step - accuracy: 0.9733 - loss: 0.0677\n","Epoch 48/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 47ms/step - accuracy: 0.9720 - loss: 0.0631\n","Epoch 49/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - accuracy: 0.9836 - loss: 0.0477\n","Epoch 50/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 49ms/step - accuracy: 0.9842 - loss: 0.0411\n","Epoch 51/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - accuracy: 0.9817 - loss: 0.0629\n","Epoch 52/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - accuracy: 0.9804 - loss: 0.0494\n","Epoch 53/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.9871 - loss: 0.0355\n","Epoch 54/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - accuracy: 0.9780 - loss: 0.0647\n","Epoch 55/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.9823 - loss: 0.0485\n","Epoch 56/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - accuracy: 0.9568 - loss: 0.1029\n","Epoch 57/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.9737 - loss: 0.0650\n","Epoch 58/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 53ms/step - accuracy: 0.9857 - loss: 0.0407\n","Epoch 59/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - accuracy: 0.9860 - loss: 0.0320\n","Epoch 60/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9848 - loss: 0.0503\n","Epoch 61/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.9843 - loss: 0.0428\n","Epoch 62/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.9858 - loss: 0.0456\n","Epoch 63/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - accuracy: 0.9870 - loss: 0.0348\n","Epoch 64/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.9894 - loss: 0.0324\n","Epoch 65/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 46ms/step - accuracy: 0.9812 - loss: 0.0484\n","Epoch 66/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 48ms/step - accuracy: 0.9694 - loss: 0.0840\n","Epoch 67/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.9836 - loss: 0.0349\n","Epoch 68/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.9869 - loss: 0.0312\n","Epoch 69/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 48ms/step - accuracy: 0.9873 - loss: 0.0535\n","Epoch 70/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.9863 - loss: 0.0277\n","Epoch 71/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 46ms/step - accuracy: 0.9878 - loss: 0.0292\n","Epoch 72/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - accuracy: 0.9942 - loss: 0.0192\n","Epoch 73/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.9881 - loss: 0.0258\n","Epoch 74/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.9833 - loss: 0.0388\n","Epoch 75/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - accuracy: 0.9801 - loss: 0.0581\n","Epoch 76/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.9850 - loss: 0.0351\n","Epoch 77/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 47ms/step - accuracy: 0.9973 - loss: 0.0118\n","Epoch 78/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.9933 - loss: 0.0377\n","Epoch 79/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - accuracy: 0.9821 - loss: 0.0414\n","Epoch 80/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 46ms/step - accuracy: 0.9779 - loss: 0.0688\n","Epoch 81/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - accuracy: 0.9893 - loss: 0.0334\n","Epoch 82/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.9940 - loss: 0.0186\n","Epoch 83/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 50ms/step - accuracy: 0.9831 - loss: 0.0518\n","Epoch 84/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 50ms/step - accuracy: 0.9881 - loss: 0.0341\n","Epoch 85/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.9919 - loss: 0.0266\n","Epoch 86/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9913 - loss: 0.0340\n","Epoch 87/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 52ms/step - accuracy: 0.9947 - loss: 0.0179\n","Epoch 88/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.9831 - loss: 0.0674\n","Epoch 89/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.9949 - loss: 0.0163\n","Epoch 90/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 48ms/step - accuracy: 0.9980 - loss: 0.0112\n","Epoch 91/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 0.9875 - loss: 0.0343\n","Epoch 92/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.9949 - loss: 0.0157\n","Epoch 93/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - accuracy: 0.9930 - loss: 0.0261\n","Epoch 94/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.9901 - loss: 0.0302\n","Epoch 95/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 47ms/step - accuracy: 0.9820 - loss: 0.0686\n","Epoch 96/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - accuracy: 0.9868 - loss: 0.0354\n","Epoch 97/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.9853 - loss: 0.0384\n","Epoch 98/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.9895 - loss: 0.0328\n","Epoch 99/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - accuracy: 0.9848 - loss: 0.0394\n","Epoch 100/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.9902 - loss: 0.0316\n","\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","✅ Predictions saved to: /content/drive/MyDrive/Colab Notebooks/Bangla_new/Bangla_Predictions_Result.csv\n"]}]},{"cell_type":"code","source":["# VULGAR\n","\n","import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.utils import class_weight\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","\n","import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Dense, Dropout, Concatenate, BatchNormalization\n","\n","# ----------------------------\n","# STEP 1: Prepare Labels\n","# ----------------------------\n","le = LabelEncoder()\n","y = le.fit_transform(df['Vulgar'])  # df is the training DataFrame\n","print('Training label distribution:', pd.Series(y).value_counts())\n","\n","# ----------------------------\n","# STEP 2: Build the Model\n","# ----------------------------\n","\n","# 1. Text Branch\n","text_input = Input(shape=(X2.shape[1],), name='text_input')\n","text_branch = Dense(512, activation='relu')(text_input)\n","text_branch = BatchNormalization()(text_branch)\n","text_branch = Dropout(0.2)(text_branch)\n","text_branch = Dense(256, activation='relu')(text_branch)\n","text_branch = BatchNormalization()(text_branch)\n","text_branch = Dropout(0.2)(text_branch)\n","\n","# 2. Image Branch\n","image_input = Input(shape=(X1.shape[1],), name='image_input')\n","image_branch = Dense(512, activation='relu')(image_input)\n","image_branch = BatchNormalization()(image_branch)\n","image_branch = Dropout(0.2)(image_branch)\n","image_branch = Dense(256, activation='relu')(image_branch)\n","image_branch = BatchNormalization()(image_branch)\n","image_branch = Dropout(0.2)(image_branch)\n","\n","# 3. Merge Modalities\n","combined = Concatenate()([text_branch, image_branch])\n","combined = Dense(512, activation='relu')(combined)\n","combined = BatchNormalization()(combined)\n","combined = Dropout(0.2)(combined)\n","combined = Dense(256, activation='relu')(combined)\n","combined = BatchNormalization()(combined)\n","combined = Dropout(0.2)(combined)\n","combined = Dense(128, activation='relu')(combined)\n","combined = BatchNormalization()(combined)\n","combined = Dropout(0.2)(combined)\n","combined = Dense(64, activation='relu')(combined)\n","combined = BatchNormalization()(combined)\n","combined = Dropout(0.2)(combined)\n","\n","# 4. Output Layer\n","output = Dense(1, activation='sigmoid')(combined)\n","model = Model(inputs=[text_input, image_input], outputs=output)\n","\n","# ----------------------------\n","# STEP 3: Compile and Train\n","# ----------------------------\n","\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Class Weights\n","class_weights = class_weight.compute_class_weight(\n","    class_weight='balanced',\n","    classes=np.unique(y),\n","    y=y\n",")\n","class_weights = dict(enumerate(class_weights))\n","\n","# Train on full training data (no split)\n","history = model.fit([X2, X1], y,\n","                    batch_size=16,\n","                    epochs=100,\n","                    class_weight=class_weights)\n","\n","# ----------------------------\n","# STEP 4: Predict on Separate Test Dataset\n","# ----------------------------\n","\n","# Ensure test features are already loaded as:\n","# X_text_test_final, X_image_test_final\n","\n","y_pred_probs = model.predict([X_text_test_scaled, X_image_test_scaled]) # Corrected typo\n","y_pred_labels = (y_pred_probs > 0.5).astype(int).flatten()\n","\n","# Map 0 → NON-VULGAR, 1 → VULGAR\n","mapped_labels = ['Vulgar' if label == 1 else 'Non-Vulgar' for label in y_pred_labels]\n","\n","test_df['Vulgar']=mapped_labels\n","# ----------------------------\n","# STEP 5: Save to Google Drive\n","# ----------------------------\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","output_path = '/content/drive/MyDrive/Colab Notebooks/Bangla_new/Bangla_Predictions_Result.csv'\n","test_df.to_csv(output_path, index=False)\n","print(f\"✅ Predictions saved to: {output_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H5UNQpZR8Tlx","executionInfo":{"status":"ok","timestamp":1753107349239,"user_tz":-330,"elapsed":944772,"user":{"displayName":"Subham Rai","userId":"06576043812723112607"}},"outputId":"843a424b-517b-4962-c78a-e833d3f83e2e"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["Training label distribution: 0    2226\n","1     467\n","Name: count, dtype: int64\n","Epoch 1/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 50ms/step - accuracy: 0.5057 - loss: 0.8861\n","Epoch 2/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 46ms/step - accuracy: 0.5573 - loss: 0.7313\n","Epoch 3/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - accuracy: 0.6132 - loss: 0.6703\n","Epoch 4/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - accuracy: 0.6507 - loss: 0.5833\n","Epoch 5/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step - accuracy: 0.7449 - loss: 0.4802\n","Epoch 6/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.7800 - loss: 0.3819\n","Epoch 7/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.8585 - loss: 0.3096\n","Epoch 8/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - accuracy: 0.8581 - loss: 0.3290\n","Epoch 9/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - accuracy: 0.8568 - loss: 0.3248\n","Epoch 10/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - accuracy: 0.9114 - loss: 0.2029\n","Epoch 11/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - accuracy: 0.9076 - loss: 0.2191\n","Epoch 12/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - accuracy: 0.9346 - loss: 0.1500\n","Epoch 13/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 48ms/step - accuracy: 0.9218 - loss: 0.1869\n","Epoch 14/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.9214 - loss: 0.1834\n","Epoch 15/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - accuracy: 0.9244 - loss: 0.1749\n","Epoch 16/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - accuracy: 0.9460 - loss: 0.1613\n","Epoch 17/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - accuracy: 0.9455 - loss: 0.1410\n","Epoch 18/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - accuracy: 0.9314 - loss: 0.1589\n","Epoch 19/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 44ms/step - accuracy: 0.9421 - loss: 0.1367\n","Epoch 20/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 46ms/step - accuracy: 0.9469 - loss: 0.1254\n","Epoch 21/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.9468 - loss: 0.1356\n","Epoch 22/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 44ms/step - accuracy: 0.9614 - loss: 0.0992\n","Epoch 23/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 45ms/step - accuracy: 0.9469 - loss: 0.1181\n","Epoch 24/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - accuracy: 0.9553 - loss: 0.1109\n","Epoch 25/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 44ms/step - accuracy: 0.9602 - loss: 0.1053\n","Epoch 26/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 47ms/step - accuracy: 0.9566 - loss: 0.1140\n","Epoch 27/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - accuracy: 0.9586 - loss: 0.1120\n","Epoch 28/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - accuracy: 0.9640 - loss: 0.0879\n","Epoch 29/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 45ms/step - accuracy: 0.9642 - loss: 0.1019\n","Epoch 30/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - accuracy: 0.9369 - loss: 0.1505\n","Epoch 31/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 42ms/step - accuracy: 0.9609 - loss: 0.0990\n","Epoch 32/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 44ms/step - accuracy: 0.9533 - loss: 0.1251\n","Epoch 33/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - accuracy: 0.9644 - loss: 0.0976\n","Epoch 34/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step - accuracy: 0.9615 - loss: 0.1058\n","Epoch 35/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 45ms/step - accuracy: 0.9673 - loss: 0.1103\n","Epoch 36/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - accuracy: 0.9687 - loss: 0.0930\n","Epoch 37/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 52ms/step - accuracy: 0.9798 - loss: 0.0511\n","Epoch 38/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - accuracy: 0.9780 - loss: 0.0644\n","Epoch 39/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 47ms/step - accuracy: 0.9766 - loss: 0.0741\n","Epoch 40/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 52ms/step - accuracy: 0.9805 - loss: 0.0565\n","Epoch 41/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 47ms/step - accuracy: 0.9754 - loss: 0.0668\n","Epoch 42/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.9484 - loss: 0.1202\n","Epoch 43/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 52ms/step - accuracy: 0.9749 - loss: 0.0620\n","Epoch 44/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.9699 - loss: 0.0656\n","Epoch 45/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 45ms/step - accuracy: 0.9788 - loss: 0.0571\n","Epoch 46/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.9866 - loss: 0.0363\n","Epoch 47/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 48ms/step - accuracy: 0.9780 - loss: 0.0524\n","Epoch 48/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - accuracy: 0.9638 - loss: 0.0888\n","Epoch 49/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 53ms/step - accuracy: 0.9761 - loss: 0.0590\n","Epoch 50/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.9891 - loss: 0.0330\n","Epoch 51/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - accuracy: 0.9698 - loss: 0.0792\n","Epoch 52/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.9725 - loss: 0.0794\n","Epoch 53/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - accuracy: 0.9823 - loss: 0.0513\n","Epoch 54/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.9834 - loss: 0.0443\n","Epoch 55/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.9872 - loss: 0.0343\n","Epoch 56/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step - accuracy: 0.9823 - loss: 0.0562\n","Epoch 57/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.9863 - loss: 0.0548\n","Epoch 58/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.9712 - loss: 0.0793\n","Epoch 59/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.9899 - loss: 0.0321\n","Epoch 60/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.9896 - loss: 0.0289\n","Epoch 61/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step - accuracy: 0.9884 - loss: 0.0305\n","Epoch 62/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - accuracy: 0.9915 - loss: 0.0232\n","Epoch 63/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.9805 - loss: 0.0486\n","Epoch 64/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.9836 - loss: 0.0568\n","Epoch 65/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - accuracy: 0.9864 - loss: 0.0376\n","Epoch 66/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.9883 - loss: 0.0372\n","Epoch 67/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 44ms/step - accuracy: 0.9855 - loss: 0.0509\n","Epoch 68/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - accuracy: 0.9920 - loss: 0.0256\n","Epoch 69/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 53ms/step - accuracy: 0.9837 - loss: 0.0496\n","Epoch 70/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 44ms/step - accuracy: 0.9948 - loss: 0.0181\n","Epoch 71/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 48ms/step - accuracy: 0.9839 - loss: 0.0358\n","Epoch 72/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.9973 - loss: 0.0142\n","Epoch 73/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.9907 - loss: 0.0324\n","Epoch 74/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.9844 - loss: 0.0520\n","Epoch 75/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.9849 - loss: 0.0382\n","Epoch 76/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.9876 - loss: 0.0372\n","Epoch 77/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 57ms/step - accuracy: 0.9569 - loss: 0.1334\n","Epoch 78/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9824 - loss: 0.0535\n","Epoch 79/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - accuracy: 0.9889 - loss: 0.0467\n","Epoch 80/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 53ms/step - accuracy: 0.9920 - loss: 0.0295\n","Epoch 81/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - accuracy: 0.9901 - loss: 0.0324\n","Epoch 82/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 47ms/step - accuracy: 0.9910 - loss: 0.0200\n","Epoch 83/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.9891 - loss: 0.0294\n","Epoch 84/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.9828 - loss: 0.0390\n","Epoch 85/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 46ms/step - accuracy: 0.9924 - loss: 0.0163\n","Epoch 86/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 56ms/step - accuracy: 0.9904 - loss: 0.0485\n","Epoch 87/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 54ms/step - accuracy: 0.9929 - loss: 0.0225\n","Epoch 88/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.9911 - loss: 0.0365\n","Epoch 89/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.9862 - loss: 0.0429\n","Epoch 90/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.9914 - loss: 0.0298\n","Epoch 91/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - accuracy: 0.9859 - loss: 0.0395\n","Epoch 92/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.9955 - loss: 0.0185\n","Epoch 93/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.9959 - loss: 0.0154\n","Epoch 94/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - accuracy: 0.9945 - loss: 0.0209\n","Epoch 95/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.9895 - loss: 0.0351\n","Epoch 96/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.9816 - loss: 0.0434\n","Epoch 97/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - accuracy: 0.9907 - loss: 0.0394\n","Epoch 98/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.9942 - loss: 0.0131\n","Epoch 99/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 48ms/step - accuracy: 0.9956 - loss: 0.0194\n","Epoch 100/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - accuracy: 0.9962 - loss: 0.0165\n","\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","✅ Predictions saved to: /content/drive/MyDrive/Colab Notebooks/Bangla_new/Bangla_Predictions_Result.csv\n"]}]},{"cell_type":"code","source":["#Abuse\n","\n","import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.utils import class_weight\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","\n","import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Dense, Dropout, Concatenate, BatchNormalization\n","\n","# ----------------------------\n","# STEP 1: Prepare Labels\n","# ----------------------------\n","le = LabelEncoder()\n","y = le.fit_transform(df['Abuse'])  # df is the training DataFrame\n","print('Training label distribution:', pd.Series(y).value_counts())\n","\n","# ----------------------------\n","# STEP 2: Build the Model\n","# ----------------------------\n","\n","# 1. Text Branch\n","text_input = Input(shape=(X2.shape[1],), name='text_input')\n","text_branch = Dense(512, activation='relu')(text_input)\n","text_branch = BatchNormalization()(text_branch)\n","text_branch = Dropout(0.2)(text_branch)\n","text_branch = Dense(256, activation='relu')(text_branch)\n","text_branch = BatchNormalization()(text_branch)\n","text_branch = Dropout(0.2)(text_branch)\n","\n","# 2. Image Branch\n","image_input = Input(shape=(X1.shape[1],), name='image_input')\n","image_branch = Dense(512, activation='relu')(image_input)\n","image_branch = BatchNormalization()(image_branch)\n","image_branch = Dropout(0.2)(image_branch)\n","image_branch = Dense(256, activation='relu')(image_branch)\n","image_branch = BatchNormalization()(image_branch)\n","image_branch = Dropout(0.2)(image_branch)\n","\n","# 3. Merge Modalities\n","combined = Concatenate()([text_branch, image_branch])\n","combined = Dense(512, activation='relu')(combined)\n","combined = BatchNormalization()(combined)\n","combined = Dropout(0.2)(combined)\n","combined = Dense(256, activation='relu')(combined)\n","combined = BatchNormalization()(combined)\n","combined = Dropout(0.2)(combined)\n","combined = Dense(128, activation='relu')(combined)\n","combined = BatchNormalization()(combined)\n","combined = Dropout(0.2)(combined)\n","combined = Dense(64, activation='relu')(combined)\n","combined = BatchNormalization()(combined)\n","combined = Dropout(0.2)(combined)\n","\n","# 4. Output Layer\n","output = Dense(1, activation='sigmoid')(combined)\n","model = Model(inputs=[text_input, image_input], outputs=output)\n","\n","# ----------------------------\n","# STEP 3: Compile and Train\n","# ----------------------------\n","\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Class Weights\n","class_weights = class_weight.compute_class_weight(\n","    class_weight='balanced',\n","    classes=np.unique(y),\n","    y=y\n",")\n","class_weights = dict(enumerate(class_weights))\n","\n","# Train on full training data (no split)\n","history = model.fit([X2, X1], y,\n","                    batch_size=16,\n","                    epochs=100, class_weight=class_weights)\n","\n","# ----------------------------\n","# STEP 4: Predict on Separate Test Dataset\n","# ----------------------------\n","\n","\n","\n","y_pred_probs = model.predict([X_text_test_scaled, X_image_test_scaled]) # Corrected typo\n","y_pred_labels = (y_pred_probs > 0.5).astype(int).flatten()\n","\n","mapped_labels = ['Abusive' if label == 1 else 'Non-Abusive' for label in y_pred_labels]\n","\n","test_df['Abuse']=mapped_labels\n","# ----------------------------\n","# STEP 5: Save to Google Drive\n","# ----------------------------\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","output_path = '/content/drive/MyDrive/Colab Notebooks/Bangla_new/Bangla_Predictions_Result.csv'\n","test_df.to_csv(output_path, index=False)\n","print(f\"✅ Predictions saved to: {output_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cJTSjOEoT3AO","executionInfo":{"status":"ok","timestamp":1753108306567,"user_tz":-330,"elapsed":957312,"user":{"displayName":"Subham Rai","userId":"06576043812723112607"}},"outputId":"8dbda1c4-2c94-4624-c9db-382cdfe04bcb"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Training label distribution: 1    1954\n","0     739\n","Name: count, dtype: int64\n","Epoch 1/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 53ms/step - accuracy: 0.4922 - loss: 0.8521\n","Epoch 2/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step - accuracy: 0.5716 - loss: 0.7101\n","Epoch 3/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.6038 - loss: 0.6841\n","Epoch 4/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.6731 - loss: 0.5852\n","Epoch 5/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.7442 - loss: 0.4939\n","Epoch 6/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 53ms/step - accuracy: 0.7734 - loss: 0.4416\n","Epoch 7/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 54ms/step - accuracy: 0.8635 - loss: 0.3269\n","Epoch 8/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 46ms/step - accuracy: 0.8513 - loss: 0.3211\n","Epoch 9/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 49ms/step - accuracy: 0.8896 - loss: 0.2634\n","Epoch 10/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 56ms/step - accuracy: 0.8947 - loss: 0.2300\n","Epoch 11/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.9057 - loss: 0.2214\n","Epoch 12/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.9125 - loss: 0.1888\n","Epoch 13/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.9352 - loss: 0.1644\n","Epoch 14/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.9136 - loss: 0.2158\n","Epoch 15/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 52ms/step - accuracy: 0.9300 - loss: 0.1754\n","Epoch 16/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.9383 - loss: 0.1553\n","Epoch 17/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 48ms/step - accuracy: 0.9335 - loss: 0.1578\n","Epoch 18/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.9354 - loss: 0.1411\n","Epoch 19/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.9475 - loss: 0.1521\n","Epoch 20/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - accuracy: 0.9560 - loss: 0.1069\n","Epoch 21/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.9449 - loss: 0.1413\n","Epoch 22/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - accuracy: 0.9565 - loss: 0.1142\n","Epoch 23/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.9338 - loss: 0.1507\n","Epoch 24/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.9567 - loss: 0.1040\n","Epoch 25/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - accuracy: 0.9540 - loss: 0.1076\n","Epoch 26/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 53ms/step - accuracy: 0.9648 - loss: 0.1022\n","Epoch 27/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.9595 - loss: 0.1089\n","Epoch 28/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - accuracy: 0.9642 - loss: 0.0927\n","Epoch 29/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.9449 - loss: 0.1350\n","Epoch 30/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9693 - loss: 0.0930\n","Epoch 31/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - accuracy: 0.9658 - loss: 0.0954\n","Epoch 32/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.9451 - loss: 0.1452\n","Epoch 33/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 54ms/step - accuracy: 0.9623 - loss: 0.1001\n","Epoch 34/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 49ms/step - accuracy: 0.9564 - loss: 0.1165\n","Epoch 35/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 57ms/step - accuracy: 0.9646 - loss: 0.0980\n","Epoch 36/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 54ms/step - accuracy: 0.9589 - loss: 0.1097\n","Epoch 37/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.9745 - loss: 0.0744\n","Epoch 38/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 60ms/step - accuracy: 0.9683 - loss: 0.0885\n","Epoch 39/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 57ms/step - accuracy: 0.9812 - loss: 0.0554\n","Epoch 40/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.9775 - loss: 0.0744\n","Epoch 41/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.9822 - loss: 0.0428\n","Epoch 42/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - accuracy: 0.9718 - loss: 0.0813\n","Epoch 43/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 47ms/step - accuracy: 0.9700 - loss: 0.0931\n","Epoch 44/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.9722 - loss: 0.0694\n","Epoch 45/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - accuracy: 0.9751 - loss: 0.0681\n","Epoch 46/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - accuracy: 0.9740 - loss: 0.0654\n","Epoch 47/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.9856 - loss: 0.0455\n","Epoch 48/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - accuracy: 0.9694 - loss: 0.0830\n","Epoch 49/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.9627 - loss: 0.0969\n","Epoch 50/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.9852 - loss: 0.0444\n","Epoch 51/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - accuracy: 0.9696 - loss: 0.0831\n","Epoch 52/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.9803 - loss: 0.0598\n","Epoch 53/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - accuracy: 0.9857 - loss: 0.0431\n","Epoch 54/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.9853 - loss: 0.0480\n","Epoch 55/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.9776 - loss: 0.1117\n","Epoch 56/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 50ms/step - accuracy: 0.9838 - loss: 0.0524\n","Epoch 57/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.9808 - loss: 0.0547\n","Epoch 58/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.9811 - loss: 0.0512\n","Epoch 59/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 55ms/step - accuracy: 0.9885 - loss: 0.0346\n","Epoch 60/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.9929 - loss: 0.0288\n","Epoch 61/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 57ms/step - accuracy: 0.9861 - loss: 0.0426\n","Epoch 62/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 53ms/step - accuracy: 0.9833 - loss: 0.0480\n","Epoch 63/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 47ms/step - accuracy: 0.9725 - loss: 0.0853\n","Epoch 64/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - accuracy: 0.9802 - loss: 0.0598\n","Epoch 65/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 53ms/step - accuracy: 0.9862 - loss: 0.0375\n","Epoch 66/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 47ms/step - accuracy: 0.9911 - loss: 0.0299\n","Epoch 67/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.9566 - loss: 0.1127\n","Epoch 68/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 55ms/step - accuracy: 0.9677 - loss: 0.1538\n","Epoch 69/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 47ms/step - accuracy: 0.9796 - loss: 0.0479\n","Epoch 70/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 53ms/step - accuracy: 0.9836 - loss: 0.0621\n","Epoch 71/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.9863 - loss: 0.0378\n","Epoch 72/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.9934 - loss: 0.0295\n","Epoch 73/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 48ms/step - accuracy: 0.9954 - loss: 0.0151\n","Epoch 74/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.9899 - loss: 0.0279\n","Epoch 75/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.9889 - loss: 0.0379\n","Epoch 76/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.9863 - loss: 0.0494\n","Epoch 77/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - accuracy: 0.9787 - loss: 0.0576\n","Epoch 78/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - accuracy: 0.9930 - loss: 0.0251\n","Epoch 79/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.9709 - loss: 0.0882\n","Epoch 80/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 47ms/step - accuracy: 0.9881 - loss: 0.0328\n","Epoch 81/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 45ms/step - accuracy: 0.9907 - loss: 0.0222\n","Epoch 82/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.9933 - loss: 0.0257\n","Epoch 83/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - accuracy: 0.9974 - loss: 0.0084\n","Epoch 84/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.9894 - loss: 0.0299\n","Epoch 85/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 47ms/step - accuracy: 0.9823 - loss: 0.0464\n","Epoch 86/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - accuracy: 0.9876 - loss: 0.0389\n","Epoch 87/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 44ms/step - accuracy: 0.9878 - loss: 0.0393\n","Epoch 88/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 46ms/step - accuracy: 0.9926 - loss: 0.0304\n","Epoch 89/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.9798 - loss: 0.0612\n","Epoch 90/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.9813 - loss: 0.0629\n","Epoch 91/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 44ms/step - accuracy: 0.9870 - loss: 0.0446\n","Epoch 92/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - accuracy: 0.9877 - loss: 0.0321\n","Epoch 93/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 50ms/step - accuracy: 0.9895 - loss: 0.0240\n","Epoch 94/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - accuracy: 0.9861 - loss: 0.0340\n","Epoch 95/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - accuracy: 0.9855 - loss: 0.0376\n","Epoch 96/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 44ms/step - accuracy: 0.9806 - loss: 0.0617\n","Epoch 97/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - accuracy: 0.9868 - loss: 0.0516\n","Epoch 98/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9790 - loss: 0.0733\n","Epoch 99/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.9852 - loss: 0.0364\n","Epoch 100/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 52ms/step - accuracy: 0.9944 - loss: 0.0297\n","\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","✅ Predictions saved to: /content/drive/MyDrive/Colab Notebooks/Bangla_new/Bangla_Predictions_Result.csv\n"]}]},{"cell_type":"code","source":["#Target\n","import numpy as np\n","import pandas as pd\n","\n","from sklearn.utils import class_weight\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","\n","import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Dense, Dropout, Concatenate, BatchNormalization\n","\n","# ----------------------------\n","# STEP 1: Prepare Labels\n","# ----------------------------\n","from sklearn.preprocessing import LabelEncoder\n","le = LabelEncoder()\n","y = le.fit_transform(df['Target'])  # Multiclass labels\n","print(df['Target'].value_counts())\n","num_classes = len(np.unique(y))\n","\n","# ----------------------------\n","# STEP 2: Build the Model\n","# ----------------------------\n","\n","# 1. Text Branch\n","text_input = Input(shape=(X2.shape[1],), name='text_input')\n","text_branch = Dense(512, activation='relu')(text_input)\n","text_branch = BatchNormalization()(text_branch)\n","text_branch = Dropout(0.2)(text_branch)\n","text_branch = Dense(256, activation='relu')(text_branch)\n","text_branch = BatchNormalization()(text_branch)\n","text_branch = Dropout(0.2)(text_branch)\n","\n","# 2. Image Branch\n","image_input = Input(shape=(X1.shape[1],), name='image_input')\n","image_branch = Dense(512, activation='relu')(image_input)\n","image_branch = BatchNormalization()(image_branch)\n","image_branch = Dropout(0.2)(image_branch)\n","image_branch = Dense(256, activation='relu')(image_input) # Changed image_input to image_branch\n","image_branch = BatchNormalization()(image_branch)\n","image_branch = Dropout(0.2)(image_branch)\n","\n","# 3. Merge Modalities\n","combined = Concatenate()([text_branch, image_branch])\n","combined = Dense(512, activation='relu')(combined)\n","combined = BatchNormalization()(combined)\n","combined = Dropout(0.2)(combined)\n","combined = Dense(256, activation='relu')(combined)\n","combined = BatchNormalization()(combined)\n","combined = Dropout(0.2)(combined)\n","combined = Dense(128, activation='relu')(combined)\n","combined = BatchNormalization()(combined)\n","combined = Dropout(0.2)(combined)\n","combined = Dense(64, activation='relu')(combined)\n","combined = BatchNormalization()(combined)\n","combined = Dropout(0.2)(combined)\n","\n","\n","# 4. Output Layer (multiclass)\n","output = Dense(num_classes, activation='softmax')(combined)\n","\n","# 5. Model\n","model = Model(inputs=[text_input, image_input], outputs=output)\n","\n","# 6. Compile\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","# 7. Class Weights\n","class_weights = class_weight.compute_class_weight(class_weight='balanced',\n","                                                  classes=np.unique(y),\n","                                                  y=y.tolist())\n","class_weights = dict(enumerate(class_weights))\n","\n","# 8. Train\n","history = model.fit([X2, X1], y,\n","                    batch_size=16,\n","                    epochs=100,\n","                    class_weight=class_weights)\n","\n","# ----------------------------\n","# STEP 4: Predict on Separate Test Dataset\n","# ----------------------------\n","\n","pred_probs = model.predict([X_text_test_scaled, X_image_test_scaled])\n","pred_labels = np.argmax(pred_probs, axis=1)\n","\n","pred_names = le.inverse_transform(pred_labels)\n","test_df['Target'] = pred_names\n","\n","# Fill NaN values in 'Target' column with the mode of the predicted labels\n","mode_target = test_df['Target'].mode()[0]\n","test_df['Target'].fillna(mode_target, inplace=True)\n","\n","\n","# ----------------------------\n","# STEP 5: Save Predictions to Google Drive\n","# ----------------------------\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","output_path = '/content/drive/MyDrive/Colab Notebooks/Bangla_new/Bangla_Predictions_Result.csv'\n","test_df.to_csv(output_path, index=False)\n","print(f\"✅ Sentiment predictions saved to: {output_path}\")"],"metadata":{"collapsed":true,"id":"fSqNAM8Z4VWh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753108949812,"user_tz":-330,"elapsed":643055,"user":{"displayName":"Subham Rai","userId":"06576043812723112607"}},"outputId":"78ea96d3-b1ea-443e-8f13-27bc55b60466"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Target\n","Others                                              564\n","Individual                                          441\n","Individual, Political                               374\n","Political                                           244\n","Religion                                            143\n","Gender                                              123\n","Social Sub-groups                                    75\n","National Origin                                      38\n","Individual, Political, Religion                      17\n","Gender, Individual                                   14\n","Individual, Religion                                 14\n","Political, Religion                                  14\n","National Origin, Religion                            10\n","National Origin, Political                            8\n","Individual, National Origin                           6\n","Individual, National Origin, Political                5\n","National Origin, Political, Religion                  3\n","Gender, Social Sub-groups                             3\n","Gender, Individual, Political                         3\n","Political, Social Sub-groups                          3\n","Gender, Religion                                      3\n","Political, Religion, Social Sub-groups                2\n","Individual, National Origin, Religion                 2\n","Gender, Individual, Religion                          1\n","Gender, National Origin, Political                    1\n","Gender, Individual, Political, Religion               1\n","Gender, National Origin, Religion                     1\n","Gender, National Origin                               1\n","Gender, Political                                     1\n","Individual, National Origin, Political, Religion      1\n","Individual, Social Sub-groups                         1\n","National Origin, Others                               1\n","Name: count, dtype: int64\n","Epoch 1/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 28ms/step - accuracy: 0.0423 - loss: 3.8648\n","Epoch 2/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - accuracy: 0.0276 - loss: 3.7013\n","Epoch 3/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.0239 - loss: 4.0376\n","Epoch 4/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - accuracy: 0.0276 - loss: 3.2384\n","Epoch 5/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - accuracy: 0.0250 - loss: 3.6440\n","Epoch 6/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - accuracy: 0.0298 - loss: 3.4224\n","Epoch 7/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - accuracy: 0.0220 - loss: 2.6997\n","Epoch 8/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.0274 - loss: 2.5971\n","Epoch 9/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - accuracy: 0.0296 - loss: 2.5687\n","Epoch 10/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 0.0318 - loss: 2.3598\n","Epoch 11/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - accuracy: 0.0249 - loss: 2.4765\n","Epoch 12/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - accuracy: 0.0386 - loss: 2.1634\n","Epoch 13/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.0407 - loss: 2.1807\n","Epoch 14/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.0376 - loss: 1.7582\n","Epoch 15/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - accuracy: 0.0539 - loss: 1.7308\n","Epoch 16/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.0591 - loss: 1.7045\n","Epoch 17/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - accuracy: 0.0575 - loss: 1.5391\n","Epoch 18/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - accuracy: 0.0631 - loss: 1.4174\n","Epoch 19/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - accuracy: 0.0785 - loss: 1.2256\n","Epoch 20/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - accuracy: 0.0968 - loss: 1.1592\n","Epoch 21/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - accuracy: 0.1106 - loss: 1.2753\n","Epoch 22/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - accuracy: 0.0977 - loss: 1.4474\n","Epoch 23/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - accuracy: 0.1101 - loss: 0.9850\n","Epoch 24/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - accuracy: 0.1329 - loss: 0.9169\n","Epoch 25/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - accuracy: 0.1595 - loss: 0.8766\n","Epoch 26/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.1608 - loss: 0.9353\n","Epoch 27/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - accuracy: 0.1438 - loss: 0.8778\n","Epoch 28/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - accuracy: 0.1815 - loss: 0.8287\n","Epoch 29/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.1829 - loss: 0.9324\n","Epoch 30/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.2004 - loss: 0.8968\n","Epoch 31/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - accuracy: 0.1678 - loss: 1.1631\n","Epoch 32/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - accuracy: 0.1635 - loss: 0.9247\n","Epoch 33/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.1785 - loss: 0.6891\n","Epoch 34/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - accuracy: 0.2109 - loss: 0.6460\n","Epoch 35/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.2309 - loss: 0.6047\n","Epoch 36/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - accuracy: 0.2452 - loss: 0.5338\n","Epoch 37/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - accuracy: 0.2991 - loss: 0.5242\n","Epoch 38/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - accuracy: 0.2994 - loss: 0.5273\n","Epoch 39/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.3381 - loss: 0.4761\n","Epoch 40/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - accuracy: 0.3529 - loss: 0.4576\n","Epoch 41/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - accuracy: 0.2966 - loss: 0.6554\n","Epoch 42/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.3185 - loss: 0.4549\n","Epoch 43/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - accuracy: 0.3479 - loss: 0.4692\n","Epoch 44/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - accuracy: 0.3758 - loss: 0.4229\n","Epoch 45/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - accuracy: 0.3723 - loss: 0.4762\n","Epoch 46/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - accuracy: 0.3705 - loss: 0.4900\n","Epoch 47/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - accuracy: 0.3960 - loss: 0.4057\n","Epoch 48/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - accuracy: 0.3663 - loss: 0.4507\n","Epoch 49/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - accuracy: 0.3853 - loss: 0.4149\n","Epoch 50/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.3311 - loss: 0.5633\n","Epoch 51/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - accuracy: 0.3707 - loss: 0.5657\n","Epoch 52/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - accuracy: 0.3815 - loss: 0.5129\n","Epoch 53/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.3936 - loss: 0.4030\n","Epoch 54/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - accuracy: 0.4505 - loss: 0.3444\n","Epoch 55/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - accuracy: 0.4571 - loss: 0.3237\n","Epoch 56/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - accuracy: 0.4674 - loss: 0.3319\n","Epoch 57/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - accuracy: 0.4893 - loss: 0.2841\n","Epoch 58/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - accuracy: 0.5275 - loss: 0.2594\n","Epoch 59/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.5225 - loss: 0.2949\n","Epoch 60/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - accuracy: 0.5136 - loss: 0.3319\n","Epoch 61/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - accuracy: 0.5218 - loss: 0.3456\n","Epoch 62/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.4422 - loss: 0.4113\n","Epoch 63/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - accuracy: 0.4102 - loss: 0.9308\n","Epoch 64/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - accuracy: 0.3810 - loss: 0.9081\n","Epoch 65/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.3484 - loss: 1.0652\n","Epoch 66/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - accuracy: 0.3508 - loss: 0.5637\n","Epoch 67/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.3489 - loss: 0.5426\n","Epoch 68/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - accuracy: 0.3812 - loss: 0.4407\n","Epoch 69/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - accuracy: 0.4258 - loss: 0.3411\n","Epoch 70/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.4394 - loss: 0.3788\n","Epoch 71/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - accuracy: 0.4225 - loss: 0.3607\n","Epoch 72/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - accuracy: 0.4550 - loss: 0.3418\n","Epoch 73/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - accuracy: 0.4780 - loss: 0.2960\n","Epoch 74/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.5179 - loss: 0.2636\n","Epoch 75/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.5249 - loss: 0.2420\n","Epoch 76/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - accuracy: 0.5367 - loss: 0.2694\n","Epoch 77/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - accuracy: 0.5616 - loss: 0.2264\n","Epoch 78/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - accuracy: 0.4997 - loss: 0.3250\n","Epoch 79/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - accuracy: 0.5187 - loss: 0.3053\n","Epoch 80/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - accuracy: 0.5568 - loss: 0.2497\n","Epoch 81/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.5881 - loss: 0.2129\n","Epoch 82/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.6068 - loss: 0.2376\n","Epoch 83/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - accuracy: 0.5797 - loss: 0.2883\n","Epoch 84/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.6199 - loss: 0.2117\n","Epoch 85/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - accuracy: 0.6197 - loss: 0.1993\n","Epoch 86/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - accuracy: 0.6557 - loss: 0.1821\n","Epoch 87/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - accuracy: 0.6488 - loss: 0.1917\n","Epoch 88/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - accuracy: 0.6392 - loss: 0.2183\n","Epoch 89/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - accuracy: 0.6651 - loss: 0.1913\n","Epoch 90/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - accuracy: 0.6473 - loss: 0.2273\n","Epoch 91/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - accuracy: 0.6518 - loss: 0.2534\n","Epoch 92/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - accuracy: 0.6618 - loss: 0.1933\n","Epoch 93/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - accuracy: 0.6769 - loss: 0.1678\n","Epoch 94/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - accuracy: 0.6974 - loss: 0.1573\n","Epoch 95/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - accuracy: 0.6630 - loss: 0.1994\n","Epoch 96/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - accuracy: 0.7217 - loss: 0.1605\n","Epoch 97/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.7201 - loss: 0.1379\n","Epoch 98/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.7240 - loss: 0.1483\n","Epoch 99/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - accuracy: 0.7441 - loss: 0.1302\n","Epoch 100/100\n","\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.7826 - loss: 0.1202\n","\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-41-296493617.py:92: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n","The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n","\n","For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n","\n","\n","  test_df['Target'].fillna(mode_target, inplace=True)\n"]},{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","✅ Sentiment predictions saved to: /content/drive/MyDrive/Colab Notebooks/Bangla_new/Bangla_Predictions_Result.csv\n"]}]}]}